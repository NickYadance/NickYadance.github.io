var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/intro/",title:"Intro",description:"",content:""}),e.add({id:1,href:"/docs/web/",title:"Web",description:"The thing is, Web's complexity is always underestimated by rich talkers.",content:""}),e.add({id:2,href:"/docs/devops/",title:"Devops",description:"Devops ≠ dev + ops.",content:""}),e.add({id:3,href:"/docs/bigdata/",title:"Bigdata",description:"Data values nothing, not with hammer and shovel.",content:""}),e.add({id:4,href:"/docs/devops/mysql/backup/",title:"Backup",description:`Concepts # Cold Backup Full backup when database server is not running, less frequent.
Hot Backup Full backup when database server is running and serving.
Warn Backup Full backup when database server is running, but locking some tables.
Incremental Backup Partial backup when database server is running, containing only data(updates) since the last backup.
Binlog Binary format logs containing data updates. Non-Idempotent(different from MongoDB).
Slave Backup # Slave server can be used as an efficient and safe way of replicating (not backup) data, but with minimal latency.`,content:`Concepts # Cold Backup Full backup when database server is not running, less frequent.
Hot Backup Full backup when database server is running and serving.
Warn Backup Full backup when database server is running, but locking some tables.
Incremental Backup Partial backup when database server is running, containing only data(updates) since the last backup.
Binlog Binary format logs containing data updates. Non-Idempotent(different from MongoDB).
Slave Backup # Slave server can be used as an efficient and safe way of replicating (not backup) data, but with minimal latency. Also, we can back up data in slave server, instead of master server.
A minimal master-slave example(mysql 8.0):
host
export dir=\u0026lt;\u0026gt; mkdir -p \${dir}/master/mysql \${dir}/slave/mysql docker run --name=mysql -p 3307:3306 -v \${dir}/master/mysql:/var/lib/mysql -e REPLICATION_MASTER=true -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0 docker run --name=mysql-slave --link mysql:mysql -p 3308:3306 -v \${dir}/slave/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0 master
CREATE USER 'repl'@'%' IDENTIFIED WITH mysql_native_password BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; show master status; -- show current binlog file and position slave
set global server_id=2 -- non-persistent setting only for showcase CHANGE MASTER TO MASTER_HOST='172.17.0.3', MASTER_USER='repl', MASTER_PASSWORD='123456', MASTER_PORT=3306, MASTER_LOG_FILE='binlog.000002', MASTER_LOG_POS=1324; show slave status; Mysqldump \u0026amp; Binlog # DON\u0026rsquo;T use mysqldump to busy databases cuz the table locking can potentially hang all your requests for a long time.
mysqldump will dump data with binlog info, which is helpful when restoring data with combined dump\u0026amp;binlog.
mysqldump --all-databases --source-data=2 --single-transaction \u0026gt; master-dump.sql ## binlog info in master-dump.sql: ## CHANGE MASTER TO MASTER_LOG_FILE='binlog.000021', MASTER_LOG_POS=157; mysqlbinlog can read directly from remote server and behaves like a non-serving slave server.
mysqlbinlog --read-from-remote-server -u root -p --raw --stop-never binlog.000016 Use dump file and binlog to restore data.
mysql -u root -p \u0026lt; master-dump.sql mysqlbinlog -D -u root -p --start-position \u0026lt;MASTER_LOG_POS\u0026gt; [list of binlogs since MASTER_LOG_FILE] Percona Xtrabackup (Recommended) # Before using Percona, make sure that the Percona version is compatible with mysql server.
Typical backup scenarios with Percona Xtrabackup
## Backup xtrabackup --backup \\ --target-dir=\u0026lt;directory to backup\u0026gt; \\ --socket=\u0026lt;socket path, use \`show variables like '%socket%'\` to find out\u0026gt; \\ -h \u0026lt;host\u0026gt; \\ -u \u0026lt;user\u0026gt; \\ -p ## Prepare xtrabackup --prepare \\ --target-dir=\u0026lt;directory to backup\u0026gt; ## Transfer target dir to another machine maybe. ## Restore xtrabackup --copy-back \\ --target-dir=\u0026lt;directory to backup\u0026gt; \\ --datadir=\u0026lt;data directory for new server\u0026gt; Reference # MySQL数据库-binlog日志备份与增量恢复
优雅地给正在运行的 MySQL 添加从库
MySql 主库/从库
mysqlbinlog-backup
recover-deleted-database
`}),e.add({id:5,href:"/docs/devops/airflow/trigger/",title:"Trigger",description:"Process, Task and Thread # Multitasking Definition Process Definition Context Switch Definition Thread Definition Reference # python-concurrency",content:`Process, Task and Thread # Multitasking Definition Process Definition Context Switch Definition Thread Definition Reference # python-concurrency
`}),e.add({id:6,href:"/docs/bigdata/recommendation/icf/",title:"Icf",description:"Chinese special\n矩阵 # 转置矩阵 把矩阵A的行和列互相交换所产生的矩阵称为A的转置矩阵($A^T$) 矩阵相乘 如A是m×n矩阵，B是n×p矩阵，它们的乘积C是一个m×p矩阵 $$ C = AB, c_{ij}=\\sum^n_{r=1}{a_{ir}b_{rj}} $$ 理解矩阵相乘的意义 $$ 3x + 7y = 49 $$ $$ 2x + 4y = 54 $$ 的矩阵表现形式为 $$ \\begin{pmatrix} 3 \u0026amp; 7 \\\\ 2 \u0026amp; 4 \\end{pmatrix} \\ * \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 49 \\\\ 54 \\end{pmatrix}$$ 特征值和特征向量 n×n的方块矩阵A的一个特征值和对应特征向量是满足以下方程的标量以及非零向量。其中v为特征向量，$\\lambda$为特征值。 $$ Av=\\lambda v $$ 余弦相似度 # 设坐标点 $(x_1,y_1), (x_2,y_2)$ $$ cos(\\theta)=\\frac {a^2+b^2-c^2}{2ab}, c=\\sqrt {(x_1-x_2)^2+(y_1-y_2)^2} $$ $$ cos(\\theta)=\\frac {x_1 * x_2+y_1 * y_2}{\\sqrt {x_1^2+y_1^2}*\\sqrt{x_2^2+y_2^2}} $$ 推广到多个点 $$ cos(\\theta)=\\frac {\\sum{x_i * y_i}}{\\sqrt{\\sum{x_i^2}} * \\sqrt{\\sum{y_i^2}}} = \\frac {\\vec{a} * \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$",content:" Chinese special\n矩阵 # 转置矩阵 把矩阵A的行和列互相交换所产生的矩阵称为A的转置矩阵($A^T$) 矩阵相乘 如A是m×n矩阵，B是n×p矩阵，它们的乘积C是一个m×p矩阵 $$ C = AB, c_{ij}=\\sum^n_{r=1}{a_{ir}b_{rj}} $$ 理解矩阵相乘的意义 $$ 3x + 7y = 49 $$ $$ 2x + 4y = 54 $$ 的矩阵表现形式为 $$ \\begin{pmatrix} 3 \u0026amp; 7 \\\\ 2 \u0026amp; 4 \\end{pmatrix} \\ * \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 49 \\\\ 54 \\end{pmatrix}$$ 特征值和特征向量 n×n的方块矩阵A的一个特征值和对应特征向量是满足以下方程的标量以及非零向量。其中v为特征向量，$\\lambda$为特征值。 $$ Av=\\lambda v $$ 余弦相似度 # 设坐标点 $(x_1,y_1), (x_2,y_2)$ $$ cos(\\theta)=\\frac {a^2+b^2-c^2}{2ab}, c=\\sqrt {(x_1-x_2)^2+(y_1-y_2)^2} $$ $$ cos(\\theta)=\\frac {x_1 * x_2+y_1 * y_2}{\\sqrt {x_1^2+y_1^2}*\\sqrt{x_2^2+y_2^2}} $$ 推广到多个点 $$ cos(\\theta)=\\frac {\\sum{x_i * y_i}}{\\sqrt{\\sum{x_i^2}} * \\sqrt{\\sum{y_i^2}}} = \\frac {\\vec{a} * \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$\n物品相似度 # 评分矩阵 $$ \\begin{pmatrix} 0 \u0026amp; i0 \u0026amp; i1 \u0026amp; i2 \u0026amp; i3 \\\\ u_0 \u0026amp; r_{00} \u0026amp; r_{01} \u0026amp; r_{02} \u0026amp; r_{03} \\\\ u_1 \u0026amp; r_{10} \u0026amp; r_{11} \u0026amp; r_{12} \u0026amp; r_{13} \\\\ u_2 \u0026amp; r_{20} \u0026amp; r_{21} \u0026amp; r_{22} \u0026amp; r_{2 3} \\end{pmatrix} $$ 设 $\\vec{r_i}$ 为物品i的评分向量(评分矩阵的纵轴)，物品相似度为评分向量的余弦相似度 $$ w_{i,j}=\\frac {\\vec{r_i} * \\vec{r_j}}{|\\vec{r_i}| * |\\vec{r_j}|} $$\n线性回归 # 一元线性回归 $$ y=\\beta_0 + \\beta_1 x $$ 设误差为 $\\mu$ $$ y=\\beta_0 + \\beta_1 x + \\mu $$ 给定一组观测值 $xi,yi (i=1,2\\cdots ,n)$ ，设残差(真实值和预测值之差)为 $e$ ，残差平方和为 $Q$ ，$Q$ 可以作为损失函数 $$ e=y - \\hat{y} $$ $$ Q=\\sum^n_1{e^2}=\\sum^n_1{(y_i - \\hat{y_i})^2}=\\sum^n_1{(y_i-(\\beta_0 + \\beta_1 x))^2} $$ 最小二乘法求 $Q$ 最小时 $\\beta_0, \\beta_1$ 的值\nICF (basic) # 设 $\\vec{w_i}$ 为物品i的相似度向量(相似矩阵的横轴)，$\\vec{r_u}$ 为用户的评分向量(评分矩阵的横轴) $$ score_{(u,i)}=\\frac {\\vec{w_i} * \\vec{r_u}}{Sum_{\\vec{w_i}}} $$\nReference # 使用余弦相似度算法计算文本相似度\ncomprehensive-guide-on-item-based-recommendation-systems\n矩阵的本质\n线性回归\n"}),e.add({id:7,href:"/docs/bigdata/recommendation/",title:"Recommendation",description:"",content:""}),e.add({id:8,href:"/docs/devops/mysql/lock/",title:"Lock",description:"Setup CREATE DATABASE study; USE study; CREATE TABLE student_scores ( id int(11) NOT NULL, name varchar(100) NOT NULL, age tinyint(4) NOT NULL, score int(11) NOT NULL, PRIMARY KEY (id), KEY idx_name (name), KEY idx_age (age) ); INSERT INTO student_scores (id, name, age, score) VALUES (10, 'John', 11, 70), (20, 'Tom', 12, 90), (30, 'Jerry', 15, 95), (40, 'Jack', 13, 80), (50, 'Rose', 14, 85) ; SET GLOBAL innodb_status_output_locks=1; SHOW ENGINE INNODB STATUS; mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.",content:" Setup CREATE DATABASE study; USE study; CREATE TABLE student_scores ( id int(11) NOT NULL, name varchar(100) NOT NULL, age tinyint(4) NOT NULL, score int(11) NOT NULL, PRIMARY KEY (id), KEY idx_name (name), KEY idx_age (age) ); INSERT INTO student_scores (id, name, age, score) VALUES (10, 'John', 11, 70), (20, 'Tom', 12, 90), (30, 'Jerry', 15, 95), (40, 'Jack', 13, 80), (50, 'Rose', 14, 85) ; SET GLOBAL innodb_status_output_locks=1; SHOW ENGINE INNODB STATUS; mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; Lock mode # X/S X/S,REC_NOT_GAP X/S,Gap Next-key lock Row lock Gap lock Innodb lock monitor explanation # start transaction; select * from student_scores where id = 20 for update; /* +----+------+-----+-------+ | id | name | age | score | +----+------+-----+-------+ | 20 | Tom | 12 | 90 | +----+------+-----+-------+ 1 row in set (0.01 sec) RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12838 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; Primary index, value = 20 = 140x 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; First column, value = Tom 4: len 1; hex 8c; asc ;; Second column, value = 12 = 8c0x 5: len 4; hex 8000005a; asc Z;; Third column, value = 90 = 5a0x Row lock # Lock single record. Two locks generated:\nIntention lock granted in table level. IX/IS intention locks are quick-test for table level lock (X/S). Record lock granted in row level. start transaction; select * from student_scores where id = 20 for update; +----+------+-----+-------+ | id | name | age | score | +----+------+-----+-------+ | 20 | Tom | 12 | 90 | +----+------+-----+-------+ 1 row in set (0.01 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+---------------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+---------------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X,REC_NOT_GAP | GRANTED | 20 | +-----------+---------------+-------------+-----------+ 2 rows in set (0.01 sec) show engine innodb status; /* ------------ TRANSACTIONS ------------ Trx id counter 12839 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12838, ACTIVE 141 sec 2 lock struct(s), heap size 1128, 1 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 175 localhost root TABLE LOCK table `study`.`student_scores` trx id 12838 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12838 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; Primary index, value = 20 = 140x 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; First column, value = Tom 4: len 1; hex 8c; asc ;; Second column, value = 12 = 8c0x 5: len 4; hex 8000005a; asc Z;; Third column, value = 90 = 5a0x Gap lock # Especially in MySQL, there is an infimum record that is smaller than any index records of the table and a supremum record that is greater than any index records of the table.\nLock range records with one special gap locks lock_mode X locks gap before rec.\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where id \u0026lt; 20 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 5 | Nicky | 5 | 10 | | 10 | John | 11 | 70 | +----+-------+-----+-------+ 2 rows in set (0.01 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+-----------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+-----------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | 10 | | RECORD | X | GRANTED | 5 | | RECORD | X,GAP | GRANTED | 20 | +-----------+-----------+-------------+-----------+ 4 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12840 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12839, ACTIVE 110 sec 3 lock struct(s), heap size 1128, 3 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 182 localhost root TABLE LOCK table `study`.`student_scores` trx id 12839 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12839 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080110; asc ;; 3: len 4; hex 4a6f686e; asc John;; 4: len 1; hex 8b; asc ;; 5: len 4; hex 80000046; asc F;; Record lock, heap no 7 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 000000003223; asc 2#;; 2: len 7; hex 810000010c0110; asc ;; 3: len 5; hex 4e69636b79; asc Nicky;; 4: len 1; hex 85; asc ;; 5: len 4; hex 8000000a; asc ;; RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12839 lock_mode X locks gap before rec Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; 4: len 1; hex 8c; asc ;; 5: len 4; hex 8000005a; asc Z;; Next-key lock # Differ from gap lock in whether owning locks for the gap itself.\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where id \u0026lt;= 20 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 5 | Nicky | 5 | 10 | | 10 | John | 11 | 70 | | 20 | Tom | 12 | 90 | +----+-------+-----+-------+ 3 rows in set (0.00 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+-----------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+-----------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | 10 | | RECORD | X | GRANTED | 20 | | RECORD | X | GRANTED | 5 | +-----------+-----------+-------------+-----------+ 4 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12841 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12840, ACTIVE 69 sec 2 lock struct(s), heap size 1128, 3 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 192 localhost root TABLE LOCK table `study`.`student_scores` trx id 12840 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12840 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080110; asc ;; 3: len 4; hex 4a6f686e; asc John;; 4: len 1; hex 8b; asc ;; 5: len 4; hex 80000046; asc F;; Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; 4: len 1; hex 8c; asc ;; 5: len 4; hex 8000005a; asc Z;; Record lock, heap no 7 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 000000003223; asc 2#;; 2: len 7; hex 810000010c0110; asc ;; 3: len 5; hex 4e69636b79; asc Nicky;; 4: len 1; hex 85; asc ;; 5: len 4; hex 8000000a; asc ;; Secondary index # mysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where age \u0026gt; 13 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 50 | Rose | 14 | 85 | | 30 | Jerry | 15 | 95 | +----+-------+-----+-------+ 2 rows in set (0.00 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+---------------+-------------+------------------------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+---------------+-------------+------------------------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | supremum pseudo-record | | RECORD | X | GRANTED | 15, 30 | | RECORD | X | GRANTED | 14, 50 | | RECORD | X,REC_NOT_GAP | GRANTED | 30 | | RECORD | X,REC_NOT_GAP | GRANTED | 50 | +-----------+---------------+-------------+------------------------+ 6 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12842 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12841, ACTIVE 1276 sec 3 lock struct(s), heap size 1128, 5 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 198 localhost root TABLE LOCK table `study`.`student_scores` trx id 12841 lock mode IX RECORD LOCKS space id 159 page no 6 n bits 80 index idx_age of table `study`.`student_scores` trx id 12841 lock_mode X Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 1; hex 8f; asc ;; 1: len 4; hex 8000001e; asc ;; Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 1; hex 8e; asc ;; 1: len 4; hex 80000032; asc 2;; RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12841 lock_mode X locks rec but not gap Record lock, heap no 4 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000001e; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108012a; asc *;; 3: len 5; hex 4a65727279; asc Jerry;; 4: len 1; hex 8f; asc ;; 5: len 4; hex 8000005f; asc _;; Record lock, heap no 6 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000032; asc 2;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080144; asc D;; 3: len 4; hex 526f7365; asc Rose;; 4: len 1; hex 8e; asc ;; 5: len 4; hex 80000055; asc U;; Reference # understand-the-basics-of-locks-and-deadlocks-in-mysql-part-i mysql-deadlocks\n"}),e.add({id:9,href:"/docs/devops/airflow/delay/",title:"Delay",description:"",content:""}),e.add({id:10,href:"/docs/devops/mysql/isolation/",title:"Isolation",description:"Setup DROP TABLE IF EXISTS IsolationTests; CREATE TABLE IsolationTests ( Col1 INT, Col2 INT, Col3 INT ); INSERT INTO IsolationTests(Col1,Col2,Col3) SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 ; Read Uncommitted # -- T1 - T2 SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; BEGIN; BEGIN; UPDATE IsolationTests SET Col1 = 2; -- Dirty Read.",content:` Setup DROP TABLE IF EXISTS IsolationTests; CREATE TABLE IsolationTests ( Col1 INT, Col2 INT, Col3 INT ); INSERT INTO IsolationTests(Col1,Col2,Col3) SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 ; Read Uncommitted # -- T1 - T2 SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; BEGIN; BEGIN; UPDATE IsolationTests SET Col1 = 2; -- Dirty Read. DO sleep(10); SELECT * FROM IsolationTests; ROLLBACK; COMMIT; Read Committed # If the transaction isolation level is REPEATABLE READ (the default level), all consistent reads within the same transaction read the snapshot established by the first such read in that transaction. You can get a fresher snapshot for your queries by committing the current transaction and after that issuing new queries. With READ COMMITTED isolation level, each consistent read within a transaction sets and reads its own fresh snapshot.
This is called multi-versioned concurrency control. It increases transaction concurrency by split read from write and reduce locked read. By split read from write, we mean that read request in snapshot data will no more acquire lock contention with write request. It\u0026rsquo;s the optimistic read lock in transaction.
-- T1 -- T2 SET TRANSACTION ISOLATION LEVEL READ COMMITTED; SET TRANSACTION ISOLATION LEVEL READ COMMITTED; BEGIN; BEGIN; -- Before T1.update : Col1 = 1 SELECT * FROM IsolationTests; UPDATE IsolationTests SET Col1 = 2; -- After T1.update : Col1 = 2. Unrepeatable read DO sleep(10); SELECT * FROM IsolationTests; ROLLBACK; COMMIT; Repeatable Read (Default) # -- T1 -- T2 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; BEGIN; BEGIN; -- Before T1.update : Col1 = 1 SELECT * FROM IsolationTests; UPDATE IsolationTests SET Col1 = 2; DO sleep(10); -- After T1.update : Col1 = 1 ROLLBACK; SELECT * FROM IsolationTests; COMMIT; Repeatable Read (Phantom Read) # -- T1 -- T2 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; BEGIN; BEGIN; -- Before T1.commit : empty set SELECT * FROM IsolationTests where Col1=2; INSERT INTO IsolationTests values (2,2,3) COMMIT; -- After T1.commit : empty set SELECT * FROM IsolationTests where Col1=2; -- Update column, forced latest snapshot : success UPDATE IsolationTests SET Col2=3, Col3=4 where Col1=2; -- Phantom Read : Col (2, 3, 4) SELECT * FROM IsolationTests where Col1=2; COMMIT; Reference # innodb-consistent-read
sql-server-isolation-levels-by-example
`}),e.add({id:11,href:"/docs/devops/airflow/dead-lock/",title:"Dead Lock",description:"",content:""}),e.add({id:12,href:"/docs/devops/airflow/poke/",title:"Poke",description:"",content:""}),e.add({id:13,href:"/docs/bigdata/spark/dag/",title:"Dag",description:`Shuffle\u0026amp;Exchange
scala\u0026gt; val n2 = spark.range(1, 1000000) scala\u0026gt; val n2split = n2.repartition(7); scala\u0026gt; n2split.take(2).foreach(println) stage2 run take in one task, or in one concurrency Partitions
scala\u0026gt; val ds1 = spark.range(1, 1000000) scala\u0026gt; val ds2 = spark.range(1, 1000000, 2) scala\u0026gt; val ds3 = ds1.repartition(7) scala\u0026gt; val ds4 = ds2.repartition(9) scala\u0026gt; val ds5 = ds3.selectExpr(\u0026quot;id * 5 as id\u0026quot;) scala\u0026gt; val joined = ds5.join(ds4, \u0026quot;id\u0026quot;) scala\u0026gt; val sum = joined.selectExpr(\u0026quot;sum(id)\u0026quot;) Job3 \u0026amp; Job4 both run range() -\u0026gt; partition(), 10 tasks, producing partitions Job5 reads partitions with 9 tasks, broadcast result in memory cuz the result is small enough Job6 reads partitions with 7 tasks, run id * 5 -\u0026gt; join(in memory) Job7 run take with 1 task Reference # Nice Gitbook about Spark How To Read Spark DAGs`,content:`Shuffle\u0026amp;Exchange
scala\u0026gt; val n2 = spark.range(1, 1000000) scala\u0026gt; val n2split = n2.repartition(7); scala\u0026gt; n2split.take(2).foreach(println) stage2 run take in one task, or in one concurrency Partitions
scala\u0026gt; val ds1 = spark.range(1, 1000000) scala\u0026gt; val ds2 = spark.range(1, 1000000, 2) scala\u0026gt; val ds3 = ds1.repartition(7) scala\u0026gt; val ds4 = ds2.repartition(9) scala\u0026gt; val ds5 = ds3.selectExpr(\u0026quot;id * 5 as id\u0026quot;) scala\u0026gt; val joined = ds5.join(ds4, \u0026quot;id\u0026quot;) scala\u0026gt; val sum = joined.selectExpr(\u0026quot;sum(id)\u0026quot;) Job3 \u0026amp; Job4 both run range() -\u0026gt; partition(), 10 tasks, producing partitions Job5 reads partitions with 9 tasks, broadcast result in memory cuz the result is small enough Job6 reads partitions with 7 tasks, run id * 5 -\u0026gt; join(in memory) Job7 run take with 1 task Reference # Nice Gitbook about Spark How To Read Spark DAGs
`}),e.add({id:14,href:"/docs/bigdata/spark/",title:"Spark",description:"",content:""}),e.add({id:15,href:"/docs/devops/k8s/rbac/",title:"Rbac",description:`Serviceaccount with admin role for quick account setup.
--- apiVersion: v1 kind: ServiceAccount metadata: name: airflow-worker namespace: airflow --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods\u0026quot;, \u0026quot;pods/log\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods/exec\u0026quot;] verbs: [\u0026quot;create\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to roleRef: apiGroup: rbac.`,content:`Serviceaccount with admin role for quick account setup.
--- apiVersion: v1 kind: ServiceAccount metadata: name: airflow-worker namespace: airflow --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods\u0026quot;, \u0026quot;pods/log\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods/exec\u0026quot;] verbs: [\u0026quot;create\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: airflow-worker # Should match name of Role subjects: - namespace: airflow kind: ServiceAccount name: airflow-worker # Should match service account name, above `}),e.add({id:16,href:"/docs/web/java/retrofit_okhttp/",title:"Retrofit Okhttp",description:`Hope that I will never bother with making http requests in Java.
@Configuration @Slf4j public class Config { public Retrofit retrofit(ObjectMapper objectMapper, CustomProperties properties) { HttpLoggingInterceptor logging = new HttpLoggingInterceptor(message -\u0026gt; { if (log.isDebugEnabled()) { log.debug(message); } }); logging.setLevel(HttpLoggingInterceptor.Level.BODY); OkHttpClient client = new OkHttpClient.Builder() .readTimeout(Duration.ofSeconds(5L)) .writeTimeout(Duration.ofSeconds(5L)) .connectTimeout(Duration.ofSeconds(3L)) .addInterceptor(chain -\u0026gt; chain.proceed(chain.request().newBuilder() .header(\u0026quot;AUTHORIZATION-NAME\u0026quot;, properties.authName) .header(\u0026quot;AUTHORIZATION-TOKEN\u0026quot;, properties.authToken) .header(\u0026quot;DATA-ENVIRONMENT\u0026quot;, properties.authEnv) .build())) .addInterceptor(logging) .build(); return new Retrofit.Builder() .baseUrl(properties.url) .client(client) .addConverterFactory(JacksonConverterFactory.create(objectMapper)) .build(); } protected interface Service { @POST(\u0026quot;/api/post\u0026quot;) Call\u0026lt;Resposne\u0026gt; saveAndSubmit(@Body Request req); @GET(\u0026quot;/api/query\u0026quot;) Call\u0026lt;Response\u0026gt; query(@Query(value = \u0026quot;param\u0026quot;) String param); } @Bean public Service service(Retrofit retrofit) { return retrofit().`,content:`Hope that I will never bother with making http requests in Java.
@Configuration @Slf4j public class Config { public Retrofit retrofit(ObjectMapper objectMapper, CustomProperties properties) { HttpLoggingInterceptor logging = new HttpLoggingInterceptor(message -\u0026gt; { if (log.isDebugEnabled()) { log.debug(message); } }); logging.setLevel(HttpLoggingInterceptor.Level.BODY); OkHttpClient client = new OkHttpClient.Builder() .readTimeout(Duration.ofSeconds(5L)) .writeTimeout(Duration.ofSeconds(5L)) .connectTimeout(Duration.ofSeconds(3L)) .addInterceptor(chain -\u0026gt; chain.proceed(chain.request().newBuilder() .header(\u0026quot;AUTHORIZATION-NAME\u0026quot;, properties.authName) .header(\u0026quot;AUTHORIZATION-TOKEN\u0026quot;, properties.authToken) .header(\u0026quot;DATA-ENVIRONMENT\u0026quot;, properties.authEnv) .build())) .addInterceptor(logging) .build(); return new Retrofit.Builder() .baseUrl(properties.url) .client(client) .addConverterFactory(JacksonConverterFactory.create(objectMapper)) .build(); } protected interface Service { @POST(\u0026quot;/api/post\u0026quot;) Call\u0026lt;Resposne\u0026gt; saveAndSubmit(@Body Request req); @GET(\u0026quot;/api/query\u0026quot;) Call\u0026lt;Response\u0026gt; query(@Query(value = \u0026quot;param\u0026quot;) String param); } @Bean public Service service(Retrofit retrofit) { return retrofit().create(Service.class); } } `}),e.add({id:17,href:"/docs/devops/k8s/mysql_deploy/",title:"Mysql Deploy",description:`Single node mysql deployment.
--- apiVersion: v1 # API version kind: Service # Type of kubernetes resource metadata: name: mysql # Name of the resource labels: # Labels that will be applied to the resource app: mysql namespace: airflow spec: ports: - port: 3306 selector: app: mysql clusterIP: 10.96.144.158 --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config namespace: airflow # Extra configurations # set innodb_lock_wait_timeout=100; data: my.cnf: |- [mysqld] max_connections = 4096 binlog_expire_logs_seconds = 3600 explicit_defaults_for_timestamp = 1 --- apiVersion: apps/v1 kind: Deployment # Type of the kubernetes resource metadata: name: mysql # Name of the deployment labels: # Labels applied to this deployment app: mysql namespace: airflow spec: selector: matchLabels: # This deployment applies to the Pods matching the specified labels app: mysql strategy: type: Recreate template: # Template for the Pods in this deployment metadata: labels: # Labels to be applied to the Pods in this deployment app: mysql spec: # The spec for the containers that will be run inside the Pods in this deployment nodeSelector: database: accept tolerations: - key: node-role.`,content:"Single node mysql deployment.\n--- apiVersion: v1 # API version kind: Service # Type of kubernetes resource metadata: name: mysql # Name of the resource labels: # Labels that will be applied to the resource app: mysql namespace: airflow spec: ports: - port: 3306 selector: app: mysql clusterIP: 10.96.144.158 --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config namespace: airflow # Extra configurations # set innodb_lock_wait_timeout=100; data: my.cnf: |- [mysqld] max_connections = 4096 binlog_expire_logs_seconds = 3600 explicit_defaults_for_timestamp = 1 --- apiVersion: apps/v1 kind: Deployment # Type of the kubernetes resource metadata: name: mysql # Name of the deployment labels: # Labels applied to this deployment app: mysql namespace: airflow spec: selector: matchLabels: # This deployment applies to the Pods matching the specified labels app: mysql strategy: type: Recreate template: # Template for the Pods in this deployment metadata: labels: # Labels to be applied to the Pods in this deployment app: mysql spec: # The spec for the containers that will be run inside the Pods in this deployment nodeSelector: database: accept tolerations: - key: node-role.kubernetes.io/master operator: Equal effect: NoSchedule containers: - image: mysql:8 # The container image name: mysql securityContext: runAsUser: 0 env: # Environment variables passed to the container - name: MYSQL_ROOT_PASSWORD valueFrom: # Read environment variables from kubernetes secrets secretKeyRef: name: mysql-root-pass-96h4525584 key: password - name: MYSQL_DATABASE valueFrom: secretKeyRef: name: mysql-db-url-cdthkb6gg6 key: database - name: MYSQL_USER valueFrom: secretKeyRef: name: mysql-user-pass-2bg297f5c9 key: username - name: MYSQL_PASSWORD valueFrom: secretKeyRef: name: mysql-user-pass-2bg297f5c9 key: password ports: - containerPort: 3306 # The port that the container exposes name: mysql volumeMounts: - name: mysql-persistent-storage # This name should match the name specified in `volumes.name` mountPath: /var/lib/mysql - name: mysql-config mountPath: /etc/mysql/conf.d volumes: - name: mysql-persistent-storage hostPath: path: /mnt/airflow/data - name: mysql-config configMap: name: mysql-config "}),e.add({id:18,href:"/docs/devops/k8s/",title:"K8s",description:"",content:""}),e.add({id:19,href:"/docs/devops/ansible/example/",title:"Example",description:"--- - name: \u0026quot;k8s ops\u0026quot; # Create a hosts file , and use -i \u0026lt;host_file\u0026gt; hosts: k8s become: yes become_user: yi.wu remote_user: yi.wu tasks: - name: \u0026quot;Playbook\u0026quot; # Run shell command shell: \u0026quot;sudo docker pull alpine:3.16\u0026quot; # Command args args: # Use bash executable: \u0026quot;/bin/bash\u0026quot; # Capture output register: output - debug: var=output.stdout_lines ",content:"--- - name: \u0026quot;k8s ops\u0026quot; # Create a hosts file , and use -i \u0026lt;host_file\u0026gt; hosts: k8s become: yes become_user: yi.wu remote_user: yi.wu tasks: - name: \u0026quot;Playbook\u0026quot; # Run shell command shell: \u0026quot;sudo docker pull alpine:3.16\u0026quot; # Command args args: # Use bash executable: \u0026quot;/bin/bash\u0026quot; # Capture output register: output - debug: var=output.stdout_lines "}),e.add({id:20,href:"/docs/devops/ansible/localhost/",title:"Localhost",description:"--- - name: \u0026quot;Playing with Ansible\u0026quot; hosts: localhost connection: local tasks: - name: \u0026quot;ls -l\u0026quot; shell: \u0026quot;hostname\u0026quot; register: \u0026quot;output\u0026quot; - debug: var=output.stdout_lines ",content:"--- - name: \u0026quot;Playing with Ansible\u0026quot; hosts: localhost connection: local tasks: - name: \u0026quot;ls -l\u0026quot; shell: \u0026quot;hostname\u0026quot; register: \u0026quot;output\u0026quot; - debug: var=output.stdout_lines "}),e.add({id:21,href:"/docs/devops/ansible/",title:"Ansible",description:"",content:""}),e.add({id:22,href:"/docs/devops/airflow/google_oauth/",title:"Google Oauth",description:`Implement AirflowSecurityManager, and put it under any PYTHONPATH in Airflow.
import logging import os from typing import Any, List, Union, Dict from airflow.www.fab_security.sqla.models import Permission from airflow.www.security import AirflowSecurityManager log = logging.getLogger(__name__) log.setLevel(os.getenv(\u0026quot;AIRFLOW__LOGGING__FAB_LOGGING_LEVEL\u0026quot;, \u0026quot;INFO\u0026quot;)) FAB_ADMIN_ROLE = \u0026quot;Admin\u0026quot; FAB_OP_ROLE = \u0026quot;Op\u0026quot; FAB_VIEWER_ROLE = \u0026quot;Viewer\u0026quot; FAB_PUBLIC_ROLE = \u0026quot;Public\u0026quot; class GoogleAuthorizer(AirflowSecurityManager): def get_role_permissions_from_db(self, role_id: int) -\u0026gt; List[Permission]: pass def get_oauth_user_info( self, provider: str, resp: Any ) -\u0026gt; Dict[str, Union[str, List[str]]]: authorized_hd = 'shopee.com' me = self.`,content:`Implement AirflowSecurityManager, and put it under any PYTHONPATH in Airflow.
import logging import os from typing import Any, List, Union, Dict from airflow.www.fab_security.sqla.models import Permission from airflow.www.security import AirflowSecurityManager log = logging.getLogger(__name__) log.setLevel(os.getenv(\u0026quot;AIRFLOW__LOGGING__FAB_LOGGING_LEVEL\u0026quot;, \u0026quot;INFO\u0026quot;)) FAB_ADMIN_ROLE = \u0026quot;Admin\u0026quot; FAB_OP_ROLE = \u0026quot;Op\u0026quot; FAB_VIEWER_ROLE = \u0026quot;Viewer\u0026quot; FAB_PUBLIC_ROLE = \u0026quot;Public\u0026quot; class GoogleAuthorizer(AirflowSecurityManager): def get_role_permissions_from_db(self, role_id: int) -\u0026gt; List[Permission]: pass def get_oauth_user_info( self, provider: str, resp: Any ) -\u0026gt; Dict[str, Union[str, List[str]]]: authorized_hd = 'shopee.com' me = self.appbuilder.sm.oauth_remotes[provider].get(\u0026quot;userinfo\u0026quot;) data = me.json() log.info('google oauth user: %s', data) if data['hd'] != authorized_hd: return {\u0026quot;username\u0026quot;: \u0026quot;guest\u0026quot;, \u0026quot;role_keys\u0026quot;: [FAB_PUBLIC_ROLE]} else: return { \u0026quot;username\u0026quot;: data.get(\u0026quot;name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;role_keys\u0026quot;: [FAB_OP_ROLE], \u0026quot;first_name\u0026quot;: data.get(\u0026quot;given_name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;last_name\u0026quot;: data.get(\u0026quot;family_name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;email\u0026quot;: data.get(\u0026quot;email\u0026quot;, \u0026quot;\u0026quot;) } Update \$AIRFLOW_HOME/webserver_config.py. Note that FAB_SECURITY_MANAGER_CLASS is the full package name of the SecurityManager in step1.
import os from flask_appbuilder.const import AUTH_OAUTH basedir = os.path.abspath(os.path.dirname(__file__)) WTF_CSRF_ENABLED = True AUTH_TYPE = AUTH_OAUTH AUTH_ROLES_SYNC_AT_LOGIN = True # Checks roles on every login AUTH_USER_REGISTRATION = ( True # allow users who are not already in the FAB DB to register ) AUTH_ROLES_MAPPING = { \u0026quot;Viewer\u0026quot;: [\u0026quot;Viewer\u0026quot;], \u0026quot;Admin\u0026quot;: [\u0026quot;Admin\u0026quot;], \u0026quot;Op\u0026quot;: [\u0026quot;Op\u0026quot;], } FAB_SECURITY_MANAGER_CLASS = \u0026quot;security_manager.GoogleAuthorizer\u0026quot; GOOGLE_KEY = '' GOOGLE_SECRET_KEY = '' OAUTH_PROVIDERS = [{ 'name': 'google', 'token_key': 'access_token', 'icon': 'fa-google', 'remote_app': { 'api_base_url': 'https://www.googleapis.com/oauth2/v2/', 'client_kwargs': { 'scope': 'email profile', \u0026quot;cookie_policy\u0026quot;: \u0026quot;single_host_origin\u0026quot; }, 'access_token_url': 'https://accounts.google.com/o/oauth2/token', 'authorize_url': 'https://accounts.google.com/o/oauth2/auth', 'request_token_url': None, 'client_id': GOOGLE_KEY, 'client_secret': GOOGLE_SECRET_KEY, } }] `}),e.add({id:23,href:"/docs/devops/airflow/",title:"Airflow",description:"",content:""}),e.add({id:24,href:"/docs/devops/shell/bash/",title:"Bash",description:"script\n## sum with awk awk '{sum += $2} END {print sum}' ## ls sort by file size ls -lh . --sort=size ## cut first field command | cut -f 1 -d '=' ## cut seconds until last fields command | cut -f 2- -d '=' ## git git config --global https.proxy http://127.0.0.1:1086 git config --global https.proxy https://127.0.0.1:1086 git config --global http.proxy socks5://127.0.0.1:1086 git config --global https.proxy socks5://127.0.0.1:1086 git config --global --unset http.",content:`script
## sum with awk awk '{sum += \$2} END {print sum}' ## ls sort by file size ls -lh . --sort=size ## cut first field command | cut -f 1 -d '=' ## cut seconds until last fields command | cut -f 2- -d '=' ## git git config --global https.proxy http://127.0.0.1:1086 git config --global https.proxy https://127.0.0.1:1086 git config --global http.proxy socks5://127.0.0.1:1086 git config --global https.proxy socks5://127.0.0.1:1086 git config --global --unset http.proxy git config --global --unset https.proxy ## count lines wc -l 'find . -name \u0026quot;*.java*\u0026quot;' system
## IO iostat -xdm 1 ## CPU mpstat -P ALL lscpu | grep cpu cat /proc/cpuinfo | grep processor ## memory pmap \u0026lt;pid\u0026gt; cat /proc/\u0026lt;pid\u0026gt;/status ## os cat /proc/version uname -a lsb_release -a ## user useradd wuyi passwd wuyi usermod -aG sudo wuyi # add sudoers sudo visudo mysql
CREATE USER 'repl'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; `}),e.add({id:25,href:"/docs/devops/shell/kubectl/",title:"Kubectl",description:`check cgroup memory
ls -l /sys/fs/cgroup/memory | grep system.slice get po sort by age
kubectl get pod --sort-by=.metadata.creationTimestamp get po group by hostname
kubectl get po -o wide | awk '{print \$7}' | sort | uniq -c port forward
kubectl port-forward svc/airflow-webserver 8080:8080 --namespace airflow upsert configmap
kubectl create configmap foo --from-file foo.properties -o yaml --dry-run | kubectl apply -f - `,content:`check cgroup memory
ls -l /sys/fs/cgroup/memory | grep system.slice get po sort by age
kubectl get pod --sort-by=.metadata.creationTimestamp get po group by hostname
kubectl get po -o wide | awk '{print \$7}' | sort | uniq -c port forward
kubectl port-forward svc/airflow-webserver 8080:8080 --namespace airflow upsert configmap
kubectl create configmap foo --from-file foo.properties -o yaml --dry-run | kubectl apply -f - `}),e.add({id:26,href:"/docs/devops/shell/",title:"Shell",description:"",content:""}),e.add({id:27,href:"/docs/web/java/auth_filter/",title:"Auth Filter",description:"@Component @Slf4j @Profile(\u0026quot;!test\u0026quot;) public class GoogleAuthFilter extends OncePerRequestFilter { @Autowired GoogleAuthHolder googleAuthHolder; private void reject(HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED, \u0026quot;unauthorized\u0026quot;); } @SneakyThrows @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) { if (request.getRequestURI().startsWith(AUTH_API_PREFIX)) { var op = Optional.ofNullable(request.getHeader(KEY_TOKEN)) .map(JWT_PATTERN::matcher) .map(m -\u0026gt; m.matches() ? m.group(1) : null) .map(tokenString -\u0026gt; { try { return VERIFIER.verify(tokenString); } catch (Exception e) { log.warn(\u0026quot;GoogleAuth verify failed: {}\u0026quot;, tokenString, e); return null; } }); if (op.",content:"@Component @Slf4j @Profile(\u0026quot;!test\u0026quot;) public class GoogleAuthFilter extends OncePerRequestFilter { @Autowired GoogleAuthHolder googleAuthHolder; private void reject(HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED, \u0026quot;unauthorized\u0026quot;); } @SneakyThrows @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) { if (request.getRequestURI().startsWith(AUTH_API_PREFIX)) { var op = Optional.ofNullable(request.getHeader(KEY_TOKEN)) .map(JWT_PATTERN::matcher) .map(m -\u0026gt; m.matches() ? m.group(1) : null) .map(tokenString -\u0026gt; { try { return VERIFIER.verify(tokenString); } catch (Exception e) { log.warn(\u0026quot;GoogleAuth verify failed: {}\u0026quot;, tokenString, e); return null; } }); if (op.isPresent()) { var payload = op.get().getPayload(); googleAuthHolder.auth = new GoogleAuth((String) payload.get(\u0026quot;email\u0026quot;), (String) payload.get(\u0026quot;sub\u0026quot;), (String) payload.get(\u0026quot;name\u0026quot;), (String) payload.get(\u0026quot;picture\u0026quot;), (String) payload.get(\u0026quot;locale\u0026quot;)); chain.doFilter(request, response); } else { reject(response); } } else { chain.doFilter(request, response); } } } "}),e.add({id:28,href:"/docs/web/java/exception_handler/",title:"Exception Handler",description:"@RestControllerAdvice @Slf4j public class GlobalExceptionHandler { @ExceptionHandler({BusinessException.class}) protected Response\u0026lt;Object\u0026gt; handleBusinessException(Exception ex, WebRequest request) throws Exception { log.error(\u0026quot;business error\u0026quot;, ex); if (ex instanceof BusinessException be) { return Response.fail(be.code, be.message); } else if (ex.getCause() instanceof BusinessException cbe) { return Response.fail(cbe.code, cbe.message); } else { throw ex; } } } ",content:"@RestControllerAdvice @Slf4j public class GlobalExceptionHandler { @ExceptionHandler({BusinessException.class}) protected Response\u0026lt;Object\u0026gt; handleBusinessException(Exception ex, WebRequest request) throws Exception { log.error(\u0026quot;business error\u0026quot;, ex); if (ex instanceof BusinessException be) { return Response.fail(be.code, be.message); } else if (ex.getCause() instanceof BusinessException cbe) { return Response.fail(cbe.code, cbe.message); } else { throw ex; } } } "}),e.add({id:29,href:"/docs/web/java/request_correlation/",title:"Request Correlation",description:`Correlate request before and after Spring processing.
Add request_id to request context Add request_id to log4j MDC Add request_id to response Before request
@Configuration @Slf4j public class RequestCorrelationConfig { public static final String KEY_REQUEST_ID = \u0026quot;X-Request-Id\u0026quot;; public static final String KEY_START_TIME = \u0026quot;KEY_START_TIME\u0026quot;; public static class RequestLoggingWithTimeFilter extends CommonsRequestLoggingFilter { @Override protected boolean shouldLog(HttpServletRequest request) { return true; } @Override protected void beforeRequest(HttpServletRequest request, String message) { String requestId = request.`,content:`Correlate request before and after Spring processing.
Add request_id to request context Add request_id to log4j MDC Add request_id to response Before request
@Configuration @Slf4j public class RequestCorrelationConfig { public static final String KEY_REQUEST_ID = \u0026quot;X-Request-Id\u0026quot;; public static final String KEY_START_TIME = \u0026quot;KEY_START_TIME\u0026quot;; public static class RequestLoggingWithTimeFilter extends CommonsRequestLoggingFilter { @Override protected boolean shouldLog(HttpServletRequest request) { return true; } @Override protected void beforeRequest(HttpServletRequest request, String message) { String requestId = request.getHeader(KEY_REQUEST_ID); if (StringUtils.isBlank(requestId)) { requestId = UUID.randomUUID().toString().replace(\u0026quot;-\u0026quot;, \u0026quot;\u0026quot;); } MDC.put(KEY_REQUEST_ID, requestId); request.setAttribute(KEY_REQUEST_ID, requestId); request.setAttribute(KEY_START_TIME, System.currentTimeMillis()); log.info(message); } @Override protected void afterRequest(HttpServletRequest request, String message) { log.info(String.format(\u0026quot;cost: [%dms], %s\u0026quot;, Optional.ofNullable((Long) request.getAttribute(KEY_START_TIME)) .map(s -\u0026gt; System.currentTimeMillis() - s) .orElse(-1L), message)); // !It's potential that MDC is NOT clear correctly. MDC.clear(); } } @Bean public FilterRegistrationBean\u0026lt;RequestLoggingWithTimeFilter\u0026gt; registerRequestLoggingFilter() { var filter = new RequestLoggingWithTimeFilter(); filter.setIncludeQueryString(true); filter.setIncludePayload(true); filter.setMaxPayloadLength(10000); filter.setIncludeHeaders(false); filter.setAfterMessagePrefix(\u0026quot;After request: \u0026quot;); var bean = new FilterRegistrationBean\u0026lt;\u0026gt;(filter); bean.setFilter(filter); bean.setOrder(Ordered.HIGHEST_PRECEDENCE); return bean; } } After request
@RestControllerAdvice public class RequestCorrelationResponseBodyAdvice implements ResponseBodyAdvice\u0026lt;Response\u0026gt; { @Override public boolean supports(MethodParameter returnType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converterType) { return returnType.getParameterType() == Response.class; } @Override public Response beforeBodyWrite(Response body, MethodParameter returnType, MediaType selectedContentType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) { if (body != null \u0026amp;\u0026amp; request instanceof ServletServerHttpRequest) { String requestId = ((ServletServerHttpRequest) request).getServletRequest().getAttribute(RequestCorrelationConfig.KEY_REQUEST_ID).toString(); return body.requestId(requestId); } else { return body; } } } `}),e.add({id:30,href:"/docs/web/java/mdcthreadpool/",title:"MDCThreadpool",description:`Useful thread pool wrapper to pass MDC context across threads.
public class MDCThreadPoolExecutor implements ExecutorService { protected ExecutorService executorService; MDCThreadPoolExecutor() { } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this.executorService = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this.`,content:`Useful thread pool wrapper to pass MDC context across threads.
public class MDCThreadPoolExecutor implements ExecutorService { protected ExecutorService executorService; MDCThreadPoolExecutor() { } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this.executorService = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); } @Override public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { return executorService.submit(MDCWrappers.wrap(task)); } @Override public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result) { return executorService.submit(MDCWrappers.wrap(task), result); } @Override public Future\u0026lt;?\u0026gt; submit(Runnable task) { return executorService.submit(MDCWrappers.wrap(task)); } @Override public \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException { return executorService.invokeAll(MDCWrappers.wrapCollection(tasks)); } @Override public \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { return executorService.invokeAll(MDCWrappers.wrapCollection(tasks), timeout, unit); } @Override public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException { return executorService.invokeAny(MDCWrappers.wrapCollection(tasks)); } @Override public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return executorService.invokeAny(MDCWrappers.wrapCollection(tasks), timeout, unit); } @Override public void execute(Runnable command) { executorService.execute(MDCWrappers.wrap(command)); } @Override public void shutdown() { executorService.shutdown(); } @Override public List\u0026lt;Runnable\u0026gt; shutdownNow() { return executorService.shutdownNow(); } @Override public boolean isShutdown() { return executorService.isShutdown(); } @Override public boolean isTerminated() { return executorService.isTerminated(); } @Override public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { return executorService.awaitTermination(timeout, unit); } } public class MDCWrappers { public static Runnable wrap(final Runnable runnable) { final var context = MDC.getCopyOfContextMap(); return () -\u0026gt; { var previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { runnable.run(); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Callable\u0026lt;T\u0026gt; wrap(final Callable\u0026lt;T\u0026gt; callable) { final var context = MDC.getCopyOfContextMap(); return () -\u0026gt; { var previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { return callable.call(); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; wrap(final Consumer\u0026lt;T\u0026gt; consumer) { final Map\u0026lt;String, String\u0026gt; context = MDC.getCopyOfContextMap(); return (t) -\u0026gt; { Map previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { consumer.accept(t); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Collection\u0026lt;Callable\u0026lt;T\u0026gt;\u0026gt; wrapCollection(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) { Collection\u0026lt;Callable\u0026lt;T\u0026gt;\u0026gt; wrapped = new ArrayList\u0026lt;\u0026gt;(); for (Callable\u0026lt;T\u0026gt; task : tasks) { wrapped.add(wrap(task)); } return wrapped; } } `}),e.add({id:31,href:"/docs/devops/mysql/client/",title:"Client",description:`create user
CREATE USER 'repl'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; find out the latest deadlocks
show engine innodb status; show transactions
select trx_id, trx_state, trx_mysql_thread_id, trx_query from information_schema.innodb_trx; show processeslist
SHOW FULL PROCESSLIST; kill processes
kill \u0026lt;mysql_thread_id\u0026gt;; get\u0026amp;set variables
show variables like \u0026quot;max_connections\u0026quot;; set global max_connections = 200; count select qps
show global status like \u0026quot;Com_select\u0026quot;; do sleep(10); show global status like \u0026quot;Com_select\u0026quot;; `,content:`create user
CREATE USER 'repl'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; find out the latest deadlocks
show engine innodb status; show transactions
select trx_id, trx_state, trx_mysql_thread_id, trx_query from information_schema.innodb_trx; show processeslist
SHOW FULL PROCESSLIST; kill processes
kill \u0026lt;mysql_thread_id\u0026gt;; get\u0026amp;set variables
show variables like \u0026quot;max_connections\u0026quot;; set global max_connections = 200; count select qps
show global status like \u0026quot;Com_select\u0026quot;; do sleep(10); show global status like \u0026quot;Com_select\u0026quot;; `}),e.add({id:32,href:"/docs/devops/mysql/",title:"Mysql",description:"",content:""}),e.add({id:33,href:"/docs/web/golang/distributed_lock/",title:"Distributed Lock",description:`Easy to use Etcd distributed lock, some design pattern are worth thinking.
func (child *Children) WantsToPlay(computer *Computer, timeToEat *sync.WaitGroup) error { defer timeToEat.Done() fmt.Printf(\u0026quot;%s wants to play\\n\u0026quot;, child.name) session, err := concurrency.NewSession(computer.cpu, concurrency.WithTTL(10000)) if err != nil { return err } defer session.Close() seat := concurrency.NewMutex(session, computer.name) if child.isPatient { if err := seat.Lock(context.TODO()); err != nil { return err } } else { if err := seat.TryLock(context.TODO()); err != nil { if err == concurrency.`,content:`Easy to use Etcd distributed lock, some design pattern are worth thinking.
func (child *Children) WantsToPlay(computer *Computer, timeToEat *sync.WaitGroup) error { defer timeToEat.Done() fmt.Printf(\u0026quot;%s wants to play\\n\u0026quot;, child.name) session, err := concurrency.NewSession(computer.cpu, concurrency.WithTTL(10000)) if err != nil { return err } defer session.Close() seat := concurrency.NewMutex(session, computer.name) if child.isPatient { if err := seat.Lock(context.TODO()); err != nil { return err } } else { if err := seat.TryLock(context.TODO()); err != nil { if err == concurrency.ErrLocked { fmt.Printf(\u0026quot;someone else is playing, %s impatientlly leaves\\n\u0026quot;, child.name) return nil } else { return err } } } fmt.Printf(\u0026quot;%s is playing his favorite game: %s\\n\u0026quot;, child.name, child.favoriteGame) time.Sleep(time.Duration(rand.Int()%10+1) * time.Second) fmt.Printf(\u0026quot;%s is having fun\\n\u0026quot;, child.name) if err := seat.Unlock(context.TODO()); err != nil { return err } return nil } Lease And Keepalive # sequenceDiagram Client-\u0026gt;\u0026gt;+Server: Lease(ttl=T) Server--\u0026gt;\u0026gt;Client: Granted rect rgb(191, 223, 255) loop Every T/N note right of Client: Keepalive Loop. \u0026lt;br /\u0026gt;Client sends request to refresh lease every T/N, \u0026lt;br /\u0026gt; to keepalive the lease. \u0026lt;br /\u0026gt; Client-\u0026gt;\u0026gt;+Server: Refresh Lease(ttl=T) Server--\u0026gt;\u0026gt;-Client: Refershed end end Client-\u0026gt;\u0026gt;Server: I'm done Server--\u0026gt;\u0026gt;-Client: Released Reference # How Linux Cron Works Cron Distributed In Golang Next Distributed Lock In Etcd `}),e.add({id:34,href:"/docs/web/golang/",title:"Golang",description:"",content:""}),e.add({id:35,href:"/docs/web/java/",title:"Java",description:"",content:""}),e.add({id:36,href:"/docs/intro/dg/",title:"Welcome to the Garden",description:"These are nice trees and flowers that you can copy.",content:`
`}),e.add({id:37,href:"/docs/",title:"Docs",description:"Docs Doks.",content:`Here are some docs.
`}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()