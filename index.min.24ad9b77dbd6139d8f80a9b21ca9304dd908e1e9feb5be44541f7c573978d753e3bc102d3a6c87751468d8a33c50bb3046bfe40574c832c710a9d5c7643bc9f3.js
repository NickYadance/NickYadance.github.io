var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/intro/",title:"Intro",description:"",content:""}),e.add({id:1,href:"/docs/algorithm/matrix_chain/",title:"Matrix Chain",description:"Matrix chain and the cutting problem # Tow matrix $A1, A2$ can only multiply when $column_{A1}=row_{A2}$. $$ A_{p \\times q} * A_{q \\times r}=A_{p \\times r}, $$\nThe price of this is equal to the number of times each single element get multiplied. $$Price=p \\times q \\times r$$\nWe try to get the min price of multiply for the whole matrix chain. $$A_1A_2\u0026hellip;A_n$$\nNow we know that we can resolve this with DP, the thing is WHY and what\u0026rsquo;s the difference between this and the Cutting Problem.",content:"Matrix chain and the cutting problem # Tow matrix $A1, A2$ can only multiply when $column_{A1}=row_{A2}$. $$ A_{p \\times q} * A_{q \\times r}=A_{p \\times r}, $$\nThe price of this is equal to the number of times each single element get multiplied. $$Price=p \\times q \\times r$$\nWe try to get the min price of multiply for the whole matrix chain. $$A_1A_2\u0026hellip;A_n$$\nNow we know that we can resolve this with DP, the thing is WHY and what\u0026rsquo;s the difference between this and the Cutting Problem.\nRemember that DP needs these\nThe optimal substructure. The repeated subproblems. The cutting problem has, more obviously, the optimal substructure because each time we cut, we got only one sub problem. Naturally we just tried all the cutting and resolve the sub problem recursively without even thinking about the word optimal. Actually during the loop process we already picked the best result from all the sub problems, thus the optimal one. We can still prove it using the cut\u0026amp;paste method.\nThings get a little more complicated in the matrix chain as we get two sub problems each time, the left matrix chain and the right matrix chain. But still, we can try all the cutting point in the matrix chain and get the min price, exactly the same as in the cutting one.\nSo the key to find out the optimal substructure is how to get the best result from the best results. We can simplify the pattern of DP with this method.\nDefine the answer as the best result. Define how to get the best result from all the possible best results. Utilize some containers to memorize the best result to avoid wasting time. Now let\u0026rsquo;s try to resolve the matrix chain problem following the 3 steps above.\nDP: Step by step # Define the answer as the best result. The answer is the matrix chain that has the lowest multiply price.\nDefine how to get the best result from all the possible best results. $$ row_{A_k}=p(k-1), \\ column_{A_k}=p(k) \\\\ \\begin{aligned} MinPrice_{[i,j]}=Min(MinPrice_{[i,r]} + MinPrice_{[r+1,j]} + A_{p(i-1) \\times p(r)} * A_{p(r) \\times p(j)}) \\\\ =Min(MinPrice_{[i,r]} + MinPrice_{[r+1,j]} + p(i-1) \\times p(r) \\times p(j)) \\\\ \\end{aligned} $$\nUtilize some containers to memorize the best result to avoid wasting time. Let m[i, j] be the min price of matrix chain from A_i to A_j.\nPersuade code\nMinPriceOfMatrixChain(p, n): let m = array[n][n] for i in 1 to n : m[i][i] = 0 for i in n to 1 : for j in i to n : for r in i to j : m[i][j]=Min(m[i][j], m[i][r] + m[r+1][j] + p(i-1)*p(r)*p(j)) return m[1][n] Code\n"}),e.add({id:2,href:"/docs/eng/",title:"Eng",description:"",content:""}),e.add({id:3,href:"/docs/lang/",title:"Lang",description:"",content:""}),e.add({id:4,href:"/docs/algorithm/dp/",title:"DP",description:"Cutting problem # The cutting problem is to get the max profit while cutting the stick of length n $P(n)$, into many parts with any length, each length of part have its own price $p(i)$.\nDP and divide\u0026amp;conquer # The divide\u0026amp;conquer divides the problem into subproblems and merge their results, all the subproblems never repeat nor overlap.\nThe DP(dynamic programming) divides the problem into subproblems and some subproblems can repeat but not overlap.",content:"Cutting problem # The cutting problem is to get the max profit while cutting the stick of length n $P(n)$, into many parts with any length, each length of part have its own price $p(i)$.\nDP and divide\u0026amp;conquer # The divide\u0026amp;conquer divides the problem into subproblems and merge their results, all the subproblems never repeat nor overlap.\nThe DP(dynamic programming) divides the problem into subproblems and some subproblems can repeat but not overlap.\nWhen repeatable subproblems happen, DP utilizes the memorized table to get the result instantly to avoid wasting time.\nThe DP applies to the problems that are:\nHaving the optimal substructure. Having the repeated subproblems. The explosive recursion # Cutting problem - recursion public static int cuttingProblem_recursion(int length, int[] record) { int maxProfit = 0; for (int i = 1; i \u0026lt;= length; i++) { int profit = p[i] + cuttingProblem_recursion(length - i, record); if (profit \u0026gt; maxProfit) { maxProfit = profit; record[length] = i; } } return maxProfit; } For the cutting problem, the simple approach is to try all the possible cuttings. $$ P(n)=Max(p(i) + P(n-i)), i \\in [1,n] $$\nThe recursive tree of the simple approach looks like this with repeated subproblems exist: $P(2), \\ P(1), \\ P(0)$\n$T(n)$ is the number of times that cuttingProblem_recursive get called. $$ T(n) = 1 + \\sum_{i=0}^{n-1}{T(i)}, \\ T(0)=1 $$ $$ T(n) = 2^n $$\nThe graphical representation of DP: the subproblems graph # Cutting problem - dp - up public static int cuttingProblem_dp_up(int length, int[] record) { int[] memorizedTable = new int[1 + length]; for (int i = 1; i \u0026lt;= length; i++) { int maxProfit = 0; for (int j = 1; j \u0026lt;= i; j++) { int profit = p[j] + memorizedTable[i - j]; if (profit \u0026gt; maxProfit) { maxProfit = profit; record[i] = j; } memorizedTable[i] = maxProfit; } } return memorizedTable[length]; } Cutting problem - dp - down public static int cuttingProblem_dp_down(int length, int[] record, int[] memorizedTable) { if (memorizedTable[length] \u0026gt; 0) { return memorizedTable[length]; } int maxProfit = 0; for (int i = 1; i \u0026lt;= length; i++) { int profit = p[i] + cuttingProblem_recursive(length - i, record); if (profit \u0026gt; maxProfit) { maxProfit = profit; record[length] = i; } } memorizedTable[length] = maxProfit; return maxProfit; } The DP tries to collapse the recursive tree into the subproblems graph and avoid the repeated subproblems.\nThe optimal substructure prove: cut\u0026amp;paste # It\u0026rsquo;s not hard to figure out the substructure of the problem, the question is how to prove it being the optimal substructure.\nIn DP, the cut\u0026amp;paste approach is often used to prove the optimal substructure. Take the cutting problem for example: $$ P(n)=Max(p(i) + P(n-i)), i \\in [1,n] $$\nSuppose $P(n)$ is the answer for cutting(n), prove $P(n-i)$ is the answer for cutting(n-i). Suppose $P(n-i)$ is not the answer for cutting(n-i), then we cut $P(n-i)$ and paste $P^\u0026rsquo;(n-i)$ into the answer. Now we have $P^\u0026rsquo;(n-i) + p(i)$ as answer to cutting(n) which validates $P(n)$ being the answer. It might seem that all problems with substructure can be proved with cut\u0026amp;paste. A negative example is the longest simple path in a graph.\nThe path $q \\to r \\to t$ is the answer for path(q,t), but $q \\to s \\to t \\to r$ is the answer for path(q,r).\nThe reason cut\u0026amp;paste not working is that the subproblems overlapped. The $t$ appears in both answer to path(q,t) and path(q,r), which violates the definition of the longest simple path.\n"}),e.add({id:5,href:"/docs/algorithm/linearsort/",title:"Linearsort",description:"Decision tree in sort algorithms # The decision tree can be used to describe all effective sort algorithms based on:\nEach leaf node is one possible answer to a sort algorithm Leaf node num \u0026gt;= $N!,N=size$, so the algorithm can get all sorts orders O(algo) = length of longest_simple_path in decision tree Countingsort # The countingsort is easy to understand but also easy to misunderstand. The countingsort, based on the fact that the input number is limited to $N$, counts all numbers and relay them back in sorted order.",content:`Decision tree in sort algorithms # The decision tree can be used to describe all effective sort algorithms based on:
Each leaf node is one possible answer to a sort algorithm Leaf node num \u0026gt;= \$N!,N=size\`, so the algorithm can get all sorts orders O(algo) = length of longest_simple_path in decision tree Countingsort # The countingsort is easy to understand but also easy to misunderstand. The countingsort, based on the fact that the input number is limited to \`N\`, counts all numbers and relay them back in sorted order.
However, the key thing about countingsort is to keep the relative order in input, alias stability. So there is no sense writing countingsort as below even if it works.
MeaninglessCountingsort(A): B,C = new array for i = 1 to A.length: ++B[A[i]] k = 0 for i = 1 to B.length: while --B[i] \u0026gt; 0: A[k++] = i Countingsort(A): B = array for i = 1 to A.length: ++B[A[i]] for i = 2 to B.length: B[i] = B[i] + B[i - 1] for i = A.length to 1: C[B[A[i]]--] = A[i] Radixsort # The radixsort is most useful in sorting numbers with same length, by sorting each column from right to left.
It is based on the fact that countingsort(or other sort algorithm) is stable.
Bucketsort # Similar to countingsort,the input in bucketsort is distributed in a certain range, say [0, 1], but is uncountable. So the bucketsort distributes the inputs into bucket in which an ordered list receive them, and then combine results of all the buckets(lists).
`}),e.add({id:6,href:"/docs/eng/k8s/cert/",title:"Cert",description:"Public key encryption # A message is encrypted with the intended recipient\u0026rsquo;s public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message. Digital signatures # Digital signatures, in which a message is signed with the sender\u0026rsquo;s private key and can be verified by anyone who has access to the sender\u0026rsquo;s public key.",content:`Public key encryption # A message is encrypted with the intended recipient\u0026rsquo;s public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message. Digital signatures # Digital signatures, in which a message is signed with the sender\u0026rsquo;s private key and can be verified by anyone who has access to the sender\u0026rsquo;s public key. This verification proves that the sender had access to the private key, and therefore is very likely to be the person associated with the public key. It also proves that the signature was prepared for that exact message, since verification will fail for any other message one could devise without using the private key.
Certificate authorities # TLS procedure # TLS CSDN
`}),e.add({id:7,href:"/docs/algorithm/quick_sort/",title:"Quicksort",description:"Divide and Conquer # QuickSort(A, l, r): * if l \u0026lt; r : * p = Partition(A, l, r) * QuickSort(A, l, p - 1) * QuickSort(A, p + 1, r) Hoare Partition and Lomuto Partition # hoares-vs-lomuto-partition-scheme-quicksort\nIn Lomuto partition, the array is divided into 4 parts. For $A[l, r), i \\in [l, r), j \\in [l, r), x=A[r - 1]$ $$ \\begin{cases} V: \u0026amp;T(j)= \\begin{cases} \u0026amp;k \\in [l, i), A[k] \u0026lt;= x \\\\ \u0026amp;k \\in (i, j), A[k] \u0026gt; x \\\\ \u0026amp;k \\in [j, r), A[k] \\ ?",content:"Divide and Conquer # QuickSort(A, l, r): * if l \u0026lt; r : * p = Partition(A, l, r) * QuickSort(A, l, p - 1) * QuickSort(A, p + 1, r) Hoare Partition and Lomuto Partition # hoares-vs-lomuto-partition-scheme-quicksort\nIn Lomuto partition, the array is divided into 4 parts. For $A[l, r), i \\in [l, r), j \\in [l, r), x=A[r - 1]$ $$ \\begin{cases} V: \u0026amp;T(j)= \\begin{cases} \u0026amp;k \\in [l, i), A[k] \u0026lt;= x \\\\ \u0026amp;k \\in (i, j), A[k] \u0026gt; x \\\\ \u0026amp;k \\in [j, r), A[k] \\ ? \\ x \\end{cases} \\\\ S: \u0026amp;T(j)= i = l, j = l \\\\ L: \u0026amp;T(j+1)= A[j] \u0026lt;= x \\ ? \\ swap(A, i++, j) \\\\ E: \u0026amp;Answer= \\begin{cases} \u0026amp;k \\in [l, i), A[k] \u0026lt;= x \\\\ \u0026amp;k \\in (i, r), A[k] \u0026gt; x \\\\ \u0026amp;A[i] = x \\end{cases} \\\\ \\end{cases} $$\nThe $Loop$ swaps A[j] to A[i] if A[j] \u0026lt;= x so the variant keeps.\nPivot # The $x$ in the loop variants is called the pivot. There are several ways to choose it and the point is to have a more randomized pick to produce balanced sub results.\nPerformance # The reason being called quicksort is that the quicksort has average performance at $O(nlgn)$.\nThe partition, obviously cost O(n) for each travel. The cost of divide and conquer, however with related to how balanced the array is divided.\nThe detailed provence will be complex, conclusion is that in most conditions, the partition will produce rather balanced results. That is why it is quicker than other sort algorithms.\nCode # Quicksort public static void quickSort(int[] A) { quickSort(A, 0, A.length); } public static void quickSort(int[] A, int l, int r) { if (l \u0026lt; r) { int p = partition(A, l, r); quickSort(A, l, p); quickSort(A, p + 1, r); } } public static int partition(int[] A, int l, int r) { int x = A[r - 1]; int i = l, j = l; while (j \u0026lt; r) { if (A[j] \u0026lt;= x) { swap(A, i++, j); } ++j; } return i - 1; } "}),e.add({id:8,href:"/docs/algorithm/heap_sort/",title:"Heapsort",description:"Tree representation of array # The array(A) can be represented with a binary tree with A[0] as root, A[1] as left child of root, A[2] as right child of root\u0026hellip; Heapify # The first step of heap sort is to build a heap from an array by running heapify recursively.\nThe heapify(max) process is to retain the follow variant. For $tree(root) $ $$ \\begin{cases} \u0026amp;root.val \u0026gt;= any(tree(root.left)) \\\\ \u0026amp;root.val \u0026gt;= any(tree(root.",content:"Tree representation of array # The array(A) can be represented with a binary tree with A[0] as root, A[1] as left child of root, A[2] as right child of root\u0026hellip; Heapify # The first step of heap sort is to build a heap from an array by running heapify recursively.\nThe heapify(max) process is to retain the follow variant. For $tree(root) $ $$ \\begin{cases} \u0026amp;root.val \u0026gt;= any(tree(root.left)) \\\\ \u0026amp;root.val \u0026gt;= any(tree(root.right)) \\\\ \\end{cases} $$\nHeapify(root, size): largest = root if root.left \u0026lt; size : largest = indexOf(max(root.val, root.left.val)) if root.right \u0026lt; size : largest = indexOf(max(root.val, root.right.val)) if largest != root: swapValue(root, largest) Heapify(largest) BuildHeap(A): N = A.length for i = size / 2 to 0: Heapify(i, 2*i, 2*i + 1) Pop and swap # Now that for a fully heapfied array, pops the max element and swaps it to begin/end, and run heapify against the remain part of the array.\nSort(A): for i = A.length - 1 to 0: swap(A, 0, i) heapify(0, i) Code # Heapsort public static void heapify(int[] A, int root, int size) { int largest = root; int left = 2 * root + 1, right = left + 1; if (left \u0026lt; size \u0026amp;\u0026amp; A[left] \u0026gt; A[largest]) { largest = left; } if (right \u0026lt; size \u0026amp;\u0026amp; A[right] \u0026gt; A[largest]) { largest = right; } if (root != largest) { swap(A, root, largest); heapify(A, largest, size); } } public static void buildHeap(int[] A) { int size = A.length; for (int i = size / 2 - 1; i \u0026gt;= 0; i--) { heapify(A, i, size); } } public static void heapSort(int[] A) { buildHeap(A); int size = A.length; for (int i = size - 1; i \u0026gt;= 0; i--) { swap(A, 0, i); heapify(A, 0, --size); } } "}),e.add({id:9,href:"/docs/algorithm/max_subarray/",title:"Max Subarray",description:"Equivalent Stock Selling Problem # The max subarray problem can be easily transferred into stock selling problem, in which we need to find the max profit with buying and selling for only once. Take following stock price array for example $$[1\\ 3\\ 7\\ 5\\ 8\\ 2]$$ The equivalent input for max subarray is $$[2\\ 4\\ -2\\ 3\\ -6]$$ The answer is 7 for both problems.\nDivide and Conquer # As in mergesort, we follow the 3 procedures of divide and conquer.",content:"Equivalent Stock Selling Problem # The max subarray problem can be easily transferred into stock selling problem, in which we need to find the max profit with buying and selling for only once. Take following stock price array for example $$[1\\ 3\\ 7\\ 5\\ 8\\ 2]$$ The equivalent input for max subarray is $$[2\\ 4\\ -2\\ 3\\ -6]$$ The answer is 7 for both problems.\nDivide and Conquer # As in mergesort, we follow the 3 procedures of divide and conquer.\nDivide : binary-divide the array Resolve : when the array holds only 1 element, return it Conquer : the result is either the left result, or right result, or crossing dividing element As with recursive tree in mergesort, we can get the result of $T(n)=O(n\\log(n))$ $$ T(n)= \\begin{cases} 1, \u0026amp;n=1 \\\\ 2T(n/2)+n \u0026amp;n\u0026gt;1 \\\\ \\end{cases} $$\nDivide and Conquer public static class Subarray { int l; int r; int value; Subarray(int l, int r, int value) { this.l = l; this.r = r; this.value = value; } Subarray() { this.l = this.r = this.value = 0; } @Override public String toString() { return \u0026quot;[%d,%d,%d]\u0026quot;.formatted(l, r, value); } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Subarray subarray = (Subarray) o; return l == subarray.l \u0026amp;\u0026amp; r == subarray.r \u0026amp;\u0026amp; value == subarray.value; } @Override public int hashCode() { return Objects.hash(l, r, value); } } class Code { public static Subarray cross(int[] A, int l, int mid, int r) { var res = new Subarray(mid, mid + 1, A[mid]); int leftMax = 0, rightMax = 0; for (int i = mid - 1, leftSum = 0; i \u0026gt;= l; i--) { if ((leftSum += A[i]) \u0026gt; leftMax) { res.l = i; leftMax = leftSum; } } for (int j = mid + 1, rightSum = 0; j \u0026lt; r; j++) { if ((rightSum += A[j]) \u0026gt; rightMax) { res.r = j + 1; rightMax = rightSum; } } res.value += leftMax + rightMax; return res; } public static Subarray max_subarray(int[] A, int l, int r) { if (r - l \u0026gt; 1) { int mid = (r + l) / 2; var left = max_subarray(A, l, mid); var right = max_subarray(A, mid, r); var cross = cross(A, l, mid, r); return left.value \u0026gt; right.value ? (cross.value \u0026gt; left.value ? cross : left) : (cross.value \u0026gt; right.value ? cross : right); } return new Subarray(l, r, A[l]); } } Kadane algorithm # The Kadane algorithm is the linear complexity solution based on the following loop variant $$ \\begin{cases} V: \u0026amp;T(i)=max(\\sum^{i}_{k=j}{A[k]}), j \\in [0,i] \\\\ S: \u0026amp;T(i)=A[0] \\\\ L: \u0026amp;T(i+1)=T(i)\u0026gt;0\\ ?\\ T(i)+A[i+1]:A[i+1] \\\\ E: \u0026amp;Answer=max(T(i),i \\in 1\u0026hellip;n) \\\\ \\end{cases} $$ Kadane class Subarray { public static Subarray max_subarray_linear(int[] A, int l, int r) { int max = Integer.MIN_VALUE, sum = 0; int left = l, right = l; for (int i = l, currentLeft = left; i \u0026lt; r; i++) { if (sum \u0026gt; 0) { sum += A[i]; } else { sum = A[i]; currentLeft = i; } if (sum \u0026gt; max) { max = sum; left = currentLeft; right = i + 1; } } return new Subarray(left, right, max); } } "}),e.add({id:10,href:"/docs/algorithm/reverse_pair/",title:"Reverse Pair",description:` What\u0026rsquo;s the relationship between O(n) of insertion sort and reverse pair ?
A: Equal.
class ReversePair { public static int reversePair(int[] A, int l, int r) { if (r - l \u0026gt; 1) { int mid = (r + l) / 2; int n = 0; for (int i = l; i \u0026lt; mid; i++) { for (int j = mid; j \u0026lt; r; j++) { if (A[i] \u0026gt; A[j]) ++n; } } return n + reversePair(A, l, mid) + reversePair(A, mid, r); } return 0; } } `,content:` What\u0026rsquo;s the relationship between O(n) of insertion sort and reverse pair ?
A: Equal.
class ReversePair { public static int reversePair(int[] A, int l, int r) { if (r - l \u0026gt; 1) { int mid = (r + l) / 2; int n = 0; for (int i = l; i \u0026lt; mid; i++) { for (int j = mid; j \u0026lt; r; j++) { if (A[i] \u0026gt; A[j]) ++n; } } return n + reversePair(A, l, mid) + reversePair(A, mid, r); } return 0; } } `}),e.add({id:11,href:"/docs/algorithm/mergesort/",title:"Mergesort",description:"Divide And Conquer # Divide: divide the original problem to several smaller sub problems Resolve: resolve sub problems if they are small enough, or else goto step1 Conquer: merge the result of sub problems Merge Sort # MergeSort(A,l,r): if l \u0026lt; r: m=(l+r)/2 MergeSort(A,l,m) MergeSort(A,m,r) Merge(A,l,m,r) Analysis # For merge sort, when $n=2^n$ $$ T(n)= \\begin{cases} 1, \u0026amp;n=1 \\\\ 2T(n/2)+cn \u0026amp;n\u0026gt;1 \\\\ \\end{cases} $$ The recursive tree of the merge sort complexity ",content:"Divide And Conquer # Divide: divide the original problem to several smaller sub problems Resolve: resolve sub problems if they are small enough, or else goto step1 Conquer: merge the result of sub problems Merge Sort # MergeSort(A,l,r): if l \u0026lt; r: m=(l+r)/2 MergeSort(A,l,m) MergeSort(A,m,r) Merge(A,l,m,r) Analysis # For merge sort, when $n=2^n$ $$ T(n)= \\begin{cases} 1, \u0026amp;n=1 \\\\ 2T(n/2)+cn \u0026amp;n\u0026gt;1 \\\\ \\end{cases} $$ The recursive tree of the merge sort complexity "}),e.add({id:12,href:"/docs/algorithm/insertionsort/",title:"Insertion Sort",description:"Loop Variant # Let\u0026rsquo;s learn about how to prove the algorithm right with Loop Variant, which contains 4 parts: $$ \\begin{cases} Variant(V): \u0026amp;T(i) \\\\ Start(S): \u0026amp;T(0) \\\\ Loop(L): \u0026amp;T(i+1)=f(T(i)) \\\\ End(E): \u0026amp;Answer=f(T(n)) \\\\ \\end{cases} $$\nFor insertion sort $$ \\begin{cases} V: \u0026amp;T(i)=sorted(A[0,i]) \\\\ S: \u0026amp;T(0)=sorted(A[0,0]) \\\\ L: \u0026amp;T(i+1)=orderd\\_insertion(T(i), A[i+1]) \\\\ E: \u0026amp;Answer=T(n)=sorted(A[0,n]) \\\\ \\end{cases} $$\nPseudocode\nInsertionSort(A): for i=1 to A.length: j=i-1 while A[j]\u0026gt;A[i] and j \u0026gt;= 0: A[j+1]=A[j] j=j-1 A[j+1]=A[i] Analysis # For the best condition when A is ascending sorted $$t_j=1,\\ T(n)=an+b$$ For the worst condition when A is descending sorted $$t_j=j,\\ T(n)=an^2+bn+c$$",content:"Loop Variant # Let\u0026rsquo;s learn about how to prove the algorithm right with Loop Variant, which contains 4 parts: $$ \\begin{cases} Variant(V): \u0026amp;T(i) \\\\ Start(S): \u0026amp;T(0) \\\\ Loop(L): \u0026amp;T(i+1)=f(T(i)) \\\\ End(E): \u0026amp;Answer=f(T(n)) \\\\ \\end{cases} $$\nFor insertion sort $$ \\begin{cases} V: \u0026amp;T(i)=sorted(A[0,i]) \\\\ S: \u0026amp;T(0)=sorted(A[0,0]) \\\\ L: \u0026amp;T(i+1)=orderd\\_insertion(T(i), A[i+1]) \\\\ E: \u0026amp;Answer=T(n)=sorted(A[0,n]) \\\\ \\end{cases} $$\nPseudocode\nInsertionSort(A): for i=1 to A.length: j=i-1 while A[j]\u0026gt;A[i] and j \u0026gt;= 0: A[j+1]=A[j] j=j-1 A[j+1]=A[i] Analysis # For the best condition when A is ascending sorted $$t_j=1,\\ T(n)=an+b$$ For the worst condition when A is descending sorted $$t_j=j,\\ T(n)=an^2+bn+c$$\n"}),e.add({id:13,href:"/docs/algorithm/binarysearch/",title:"Binarysearch",description:"lower_bound # lower_bound of $x$ in non-descending $array[l, r)$ is the leftmost index to insert $x$ while keeping order.\nTo find the lower_bound with binary-search, keep loop invariant as below during iterations. $$ loop\\ invariant \\begin{cases} 0.\\ [l, r), \u0026amp;l\u0026lt;r \\\\ 1.\\ a[i]\u0026lt;=a[j], \u0026amp;l\u0026lt;=i\u0026lt;j\u0026lt;r \\\\ 2.\\ array[l_0]\u0026lt;array[l], \u0026amp;l_0\u0026lt;l \\\\ 3.^*\\ array[r_0]\u0026gt;=array[r], \u0026amp;r_0\u0026gt;=r \\\\ \\end{cases} $$ The invariant $3.$ can be inferred from $0,1,2$.\nBasic implementation in Java.\nclass BinarySearch { public static int lower_bound(int[] a, int target) { int l = 0, r = a.",content:"lower_bound # lower_bound of $x$ in non-descending $array[l, r)$ is the leftmost index to insert $x$ while keeping order.\nTo find the lower_bound with binary-search, keep loop invariant as below during iterations. $$ loop\\ invariant \\begin{cases} 0.\\ [l, r), \u0026amp;l\u0026lt;r \\\\ 1.\\ a[i]\u0026lt;=a[j], \u0026amp;l\u0026lt;=i\u0026lt;j\u0026lt;r \\\\ 2.\\ array[l_0]\u0026lt;array[l], \u0026amp;l_0\u0026lt;l \\\\ 3.^*\\ array[r_0]\u0026gt;=array[r], \u0026amp;r_0\u0026gt;=r \\\\ \\end{cases} $$ The invariant $3.$ can be inferred from $0,1,2$.\nBasic implementation in Java.\nclass BinarySearch { public static int lower_bound(int[] a, int target) { int l = 0, r = a.length; while (l \u0026lt; r) { int mid = (l + r) / 2; if (a[mid] \u0026lt; target) { l = mid + 1; } else { r = mid; } } return l; } } upper_bound # upper_bound of $x$ in non-descending $array[l, r)$ is the rightmost index to insert $x$ while keeping order. $$ loop\\ invariant \\begin{cases} 0.\\ [l, r), \u0026amp;l\u0026lt;r \\\\ 1.\\ a[i]\u0026lt;=a[j], \u0026amp;l\u0026lt;=i\u0026lt;j\u0026lt;r \\\\ 2.\\ array[l_0]\u0026lt;=array[l], \u0026amp;l_0\u0026lt;l \\\\ 3.^*\\ array[r_0]\u0026gt;array[r], \u0026amp;r_0\u0026gt;=r \\\\ \\end{cases} $$ The invariant $3.$ can be inferred from $0,1,2$. Specially for int array $$upper\\_bound(x)=lower\\_bound(x+1) - 1$$\nNote that when we return $l$ in upper_bound, it is the index to insert before, so for $array[1,2,3]$ and $x=2$, we return 2 instead of 1 cauze we need to insert x before.\nclass BinarySearch { public static int upper_bound(int[] a, int target) { int l = 0, r = a.length; while (l \u0026lt; r) { int mid = (l + r) / 2; if (a[mid] \u0026lt;= target) { l = mid + 1; } else { r = mid; } } return l; } } "}),e.add({id:14,href:"/docs/algorithm/simrank/",title:"Simrank",description:"",content:""}),e.add({id:15,href:"/docs/eng/airflow/bestpractice/",title:"Bestpractice",description:"Take care Database, especially Mysql # Connections IO : Airflow has heavily read ops and mid-level write ops Slow query : Airflow can make LOTS of slow queries even if the database is properly configured Clean history data Disable statsd if you can # statsd query is large, which can bring extra pressure to the db statsd can potentially crush your scheduler (#18010) Patch critical section of scheduler # Patch this (PR) if Airflow version \u0026lt;2.",content:"Take care Database, especially Mysql # Connections IO : Airflow has heavily read ops and mid-level write ops Slow query : Airflow can make LOTS of slow queries even if the database is properly configured Clean history data Disable statsd if you can # statsd query is large, which can bring extra pressure to the db statsd can potentially crush your scheduler (#18010) Patch critical section of scheduler # Patch this (PR) if Airflow version \u0026lt;2.3.4. This can really slow Airflow when dataset is large Tune scheduler configuration constantly Let Airflow do the scheduling # Use Celery or K8s to save the heavy stuff from Airflow scheduler "}),e.add({id:16,href:"/docs/eng/mysql/conf/",title:"Conf",description:`Host
Cpu: 64C Mem: 256GB Disk: SSD Initialize conf
[mysqld] max_connections = 1024 innodb_buffer_pool_size = 137438953472 # 128GB, 60-80% of the mem innodb_buffer_pool_chunk_size = 1073741824 # 1G innodb_buffer_pool_instances = 8 # 8-16 if innodb_buffer_pool_chunk_size \u0026gt;= 1G, else \u0026lt;8 innodb_flush_log_at_trx_commit = 0 # 0,1,2, take care the data safety innodb_log_buffer_size = 1073741824 # 1G innodb_log_file_size = 4294967296 # 4G tmp_table_size = 134217728 max_heap_table_size = 134217728 slow_query_log = 1 long_query_time = 5 binlog_expire_logs_seconds = 3600 innodb_page_cleaners = 4 innodb_read_io_threads = 16 innodb_write_io_threads = 16 `,content:`Host
Cpu: 64C Mem: 256GB Disk: SSD Initialize conf
[mysqld] max_connections = 1024 innodb_buffer_pool_size = 137438953472 # 128GB, 60-80% of the mem innodb_buffer_pool_chunk_size = 1073741824 # 1G innodb_buffer_pool_instances = 8 # 8-16 if innodb_buffer_pool_chunk_size \u0026gt;= 1G, else \u0026lt;8 innodb_flush_log_at_trx_commit = 0 # 0,1,2, take care the data safety innodb_log_buffer_size = 1073741824 # 1G innodb_log_file_size = 4294967296 # 4G tmp_table_size = 134217728 max_heap_table_size = 134217728 slow_query_log = 1 long_query_time = 5 binlog_expire_logs_seconds = 3600 innodb_page_cleaners = 4 innodb_read_io_threads = 16 innodb_write_io_threads = 16 `}),e.add({id:17,href:"/docs/algorithm/swing/",title:"Swing",description:"",content:""}),e.add({id:18,href:"/docs/eng/mysql/backup/",title:"Backup",description:`Concepts # Cold Backup Full backup when database server is not running, less frequent.
Hot Backup Full backup when database server is running and serving.
Warn Backup Full backup when database server is running, but locking some tables.
Incremental Backup Partial backup when database server is running, containing only data(updates) since the last backup.
Binlog Binary format logs containing data updates. Non-Idempotent(different from MongoDB).
Mysqldump \u0026amp; Binlog # DON\u0026rsquo;T use mysqldump to busy databases cuz the table locking can potentially hang all your requests for a long time.`,content:`Concepts # Cold Backup Full backup when database server is not running, less frequent.
Hot Backup Full backup when database server is running and serving.
Warn Backup Full backup when database server is running, but locking some tables.
Incremental Backup Partial backup when database server is running, containing only data(updates) since the last backup.
Binlog Binary format logs containing data updates. Non-Idempotent(different from MongoDB).
Mysqldump \u0026amp; Binlog # DON\u0026rsquo;T use mysqldump to busy databases cuz the table locking can potentially hang all your requests for a long time.
mysqldump will dump data with binlog info, which is helpful when restoring data with combined dump\u0026amp;binlog.
mysqldump --all-databases --source-data=2 --single-transaction \u0026gt; master-dump.sql ## binlog info in master-dump.sql: ## CHANGE MASTER TO MASTER_LOG_FILE='binlog.000021', MASTER_LOG_POS=157; mysqlbinlog can read directly from remote server and behaves like a non-serving slave server.
mysqlbinlog --read-from-remote-server -u root -p --raw --stop-never binlog.000016 Use dump file and binlog to restore data.
mysql -u root -p \u0026lt; master-dump.sql mysqlbinlog -D -u root -p --start-position \u0026lt;MASTER_LOG_POS\u0026gt; [list of binlogs since MASTER_LOG_FILE] Percona Xtrabackup (Recommended) # Before using Percona, make sure that the Percona version is compatible with mysql server.
Backup
xtrabackup --backup \\ --target-dir=/path/to/backup \\ --socket=\u0026lt;socket path, use \`show variables like '%socket%'\` to find out\u0026gt; \\ -H \u0026lt;host\u0026gt; \\ -u \u0026lt;user\u0026gt; \\ -p Backup with compress and stream
xtrabackup --backup \\ --target-dir=/var/lib/mysql/dump \\ --stream=xbstream \\ --compress \\ --parallel=4 \\ -H 127.0.0.1 \\ -S /var/run/mysqld/mysqld.sock \\ -u root \\ -p | ssh user@remotehost \u0026quot;xbstream -x -C /path/to/backup\u0026quot; Decompress before prepare
xtrabackup --decompress --target-dir=/path/to/backup Prepare
xtrabackup --prepare --target-dir=/path/to/backup Restore
xtrabackup --copy-back --target-dir=/path/to/backup --datadir=\u0026lt;data directory for new server\u0026gt; Slave Backup # A minimal master-slave example(mysql 8.0):
master, create repl user
CREATE USER 'repl'@'%' IDENTIFIED WITH mysql_native_password BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; show master status; -- show current binlog file and position slave, start database in docker
docker run --name mysql \\ -v /mysql/conf.d:/etc/mysql/conf.d \\ -v /mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=root \\ -p 30360:3306 \\ -d mysql:8.0 set global server_id=2; set global read_only=1; set global super_read_only=1; CHANGE MASTER TO MASTER_HOST='192.168.0.1', MASTER_USER='root', MASTER_PASSWORD='root', MASTER_PORT=30360, MASTER_LOG_FILE='binlog.029168', ## Find binlog file from data directory binlog.index MASTER_LOG_POS=724; ## Find pos from binlog file size(in byte) start slave; show slave status; ## Expected result: ## Slave_SQL_Running_State: Replica has read all relay log; waiting for more updates Reference # MySQL数据库-binlog日志备份与增量恢复
优雅地给正在运行的 MySQL 添加从库
MySql 主库/从库
mysqlbinlog-backup
recover-deleted-database
`}),e.add({id:19,href:"/docs/eng/airflow/trigger/",title:"Trigger",description:"Process, Task and Thread # Multitasking Definition Process Definition Context Switch Definition Thread Definition Reference # python-concurrency",content:`Process, Task and Thread # Multitasking Definition Process Definition Context Switch Definition Thread Definition Reference # python-concurrency
`}),e.add({id:20,href:"/docs/algorithm/icf/",title:"Icf",description:"Chinese special\n矩阵 # 转置矩阵 把矩阵A的行和列互相交换所产生的矩阵称为A的转置矩阵($A^T$) 矩阵相乘 如A是m×n矩阵，B是n×p矩阵，它们的乘积C是一个m×p矩阵 $$ C = AB, c_{ij}=\\sum^n_{r=1}{a_{ir}b_{rj}} $$ 理解矩阵相乘的意义 $$ 3x + 7y = 49 $$ $$ 2x + 4y = 54 $$ 的矩阵表现形式为 $$ \\begin{pmatrix} 3 \u0026amp; 7 \\\\ 2 \u0026amp; 4 \\end{pmatrix} \\ * \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 49 \\\\ 54 \\end{pmatrix}$$ 特征值和特征向量 n×n的方块矩阵A的一个特征值和对应特征向量是满足以下方程的标量以及非零向量。其中v为特征向量，$\\lambda$为特征值。 $$ Av=\\lambda v $$ 余弦相似度 # 设坐标点 $(x_1,y_1), (x_2,y_2)$ $$ cos(\\theta)=\\frac {a^2+b^2-c^2}{2ab}, c=\\sqrt {(x_1-x_2)^2+(y_1-y_2)^2} $$ $$ cos(\\theta)=\\frac {x_1 * x_2+y_1 * y_2}{\\sqrt {x_1^2+y_1^2}*\\sqrt{x_2^2+y_2^2}} $$ 推广到多个点 $$ cos(\\theta)=\\frac {\\sum{x_i * y_i}}{\\sqrt{\\sum{x_i^2}} * \\sqrt{\\sum{y_i^2}}} = \\frac {\\vec{a} * \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$",content:" Chinese special\n矩阵 # 转置矩阵 把矩阵A的行和列互相交换所产生的矩阵称为A的转置矩阵($A^T$) 矩阵相乘 如A是m×n矩阵，B是n×p矩阵，它们的乘积C是一个m×p矩阵 $$ C = AB, c_{ij}=\\sum^n_{r=1}{a_{ir}b_{rj}} $$ 理解矩阵相乘的意义 $$ 3x + 7y = 49 $$ $$ 2x + 4y = 54 $$ 的矩阵表现形式为 $$ \\begin{pmatrix} 3 \u0026amp; 7 \\\\ 2 \u0026amp; 4 \\end{pmatrix} \\ * \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 49 \\\\ 54 \\end{pmatrix}$$ 特征值和特征向量 n×n的方块矩阵A的一个特征值和对应特征向量是满足以下方程的标量以及非零向量。其中v为特征向量，$\\lambda$为特征值。 $$ Av=\\lambda v $$ 余弦相似度 # 设坐标点 $(x_1,y_1), (x_2,y_2)$ $$ cos(\\theta)=\\frac {a^2+b^2-c^2}{2ab}, c=\\sqrt {(x_1-x_2)^2+(y_1-y_2)^2} $$ $$ cos(\\theta)=\\frac {x_1 * x_2+y_1 * y_2}{\\sqrt {x_1^2+y_1^2}*\\sqrt{x_2^2+y_2^2}} $$ 推广到多个点 $$ cos(\\theta)=\\frac {\\sum{x_i * y_i}}{\\sqrt{\\sum{x_i^2}} * \\sqrt{\\sum{y_i^2}}} = \\frac {\\vec{a} * \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$\n物品相似度 # 评分矩阵 $$ \\begin{pmatrix} 0 \u0026amp; i0 \u0026amp; i1 \u0026amp; i2 \u0026amp; i3 \\\\ u_0 \u0026amp; r_{00} \u0026amp; r_{01} \u0026amp; r_{02} \u0026amp; r_{03} \\\\ u_1 \u0026amp; r_{10} \u0026amp; r_{11} \u0026amp; r_{12} \u0026amp; r_{13} \\\\ u_2 \u0026amp; r_{20} \u0026amp; r_{21} \u0026amp; r_{22} \u0026amp; r_{2 3} \\end{pmatrix} $$ 设 $\\vec{r_i}$ 为物品i的评分向量(评分矩阵的纵轴)，物品相似度为评分向量的余弦相似度 $$ w_{i,j}=\\frac {\\vec{r_i} * \\vec{r_j}}{|\\vec{r_i}| * |\\vec{r_j}|} $$\n线性回归 # 一元线性回归 $$ y=\\beta_0 + \\beta_1 x $$ 设误差为 $\\mu$ $$ y=\\beta_0 + \\beta_1 x + \\mu $$ 给定一组观测值 $xi,yi (i=1,2\\cdots ,n)$ ，设残差(真实值和预测值之差)为 $e$ ，残差平方和为 $Q$ ，$Q$ 可以作为损失函数 $$ e=y - \\hat{y} $$ $$ Q=\\sum^n_1{e^2}=\\sum^n_1{(y_i - \\hat{y_i})^2}=\\sum^n_1{(y_i-(\\beta_0 + \\beta_1 x))^2} $$ 最小二乘法求 $Q$ 最小时 $\\beta_0, \\beta_1$ 的值\nICF (basic) # 设 $\\vec{w_i}$ 为物品i的相似度向量(相似矩阵的横轴)，$\\vec{r_u}$ 为用户的评分向量(评分矩阵的横轴) $$ score_{(u,i)}=\\frac {\\vec{w_i} * \\vec{r_u}}{Sum_{\\vec{w_i}}} $$\nReference # 使用余弦相似度算法计算文本相似度\ncomprehensive-guide-on-item-based-recommendation-systems\n矩阵的本质\n线性回归\n"}),e.add({id:21,href:"/docs/algorithm/",title:"Algorithm",description:"",content:""}),e.add({id:22,href:"/docs/eng/mysql/lock/",title:"Lock",description:"Setup CREATE DATABASE study; USE study; CREATE TABLE student_scores ( id int(11) NOT NULL, name varchar(100) NOT NULL, age tinyint(4) NOT NULL, score int(11) NOT NULL, PRIMARY KEY (id), KEY idx_name (name), KEY idx_age (age) ); INSERT INTO student_scores (id, name, age, score) VALUES (10, 'John', 11, 70), (20, 'Tom', 12, 90), (30, 'Jerry', 15, 95), (40, 'Jack', 13, 80), (50, 'Rose', 14, 85) ; SET GLOBAL innodb_status_output_locks=1; SHOW ENGINE INNODB STATUS; mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.",content:" Setup CREATE DATABASE study; USE study; CREATE TABLE student_scores ( id int(11) NOT NULL, name varchar(100) NOT NULL, age tinyint(4) NOT NULL, score int(11) NOT NULL, PRIMARY KEY (id), KEY idx_name (name), KEY idx_age (age) ); INSERT INTO student_scores (id, name, age, score) VALUES (10, 'John', 11, 70), (20, 'Tom', 12, 90), (30, 'Jerry', 15, 95), (40, 'Jack', 13, 80), (50, 'Rose', 14, 85) ; SET GLOBAL innodb_status_output_locks=1; SHOW ENGINE INNODB STATUS; mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; Lock mode # X/S X/S,REC_NOT_GAP X/S,Gap Next-key lock Row lock Gap lock Innodb lock monitor explanation # start transaction; select * from student_scores where id = 20 for update; /* +----+------+-----+-------+ | id | name | age | score | +----+------+-----+-------+ | 20 | Tom | 12 | 90 | +----+------+-----+-------+ 1 row in set (0.01 sec) RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12838 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; Primary index, value = 20 = 140x 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; First column, value = Tom 4: len 1; hex 8c; asc ;; Second column, value = 12 = 8c0x 5: len 4; hex 8000005a; asc Z;; Third column, value = 90 = 5a0x Row lock # Lock single record. Two locks generated:\nIntention lock granted in table level. IX/IS intention locks are quick-test for table level lock (X/S). Record lock granted in row level. start transaction; select * from student_scores where id = 20 for update; +----+------+-----+-------+ | id | name | age | score | +----+------+-----+-------+ | 20 | Tom | 12 | 90 | +----+------+-----+-------+ 1 row in set (0.01 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+---------------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+---------------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X,REC_NOT_GAP | GRANTED | 20 | +-----------+---------------+-------------+-----------+ 2 rows in set (0.01 sec) show engine innodb status; /* ------------ TRANSACTIONS ------------ Trx id counter 12839 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12838, ACTIVE 141 sec 2 lock struct(s), heap size 1128, 1 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 175 localhost root TABLE LOCK table `study`.`student_scores` trx id 12838 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12838 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; Primary index, value = 20 = 140x 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; First column, value = Tom 4: len 1; hex 8c; asc ;; Second column, value = 12 = 8c0x 5: len 4; hex 8000005a; asc Z;; Third column, value = 90 = 5a0x Gap lock # Especially in MySQL, there is an infimum record that is smaller than any index records of the table and a supremum record that is greater than any index records of the table.\nLock range records with one special gap locks lock_mode X locks gap before rec.\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where id \u0026lt; 20 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 5 | Nicky | 5 | 10 | | 10 | John | 11 | 70 | +----+-------+-----+-------+ 2 rows in set (0.01 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+-----------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+-----------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | 10 | | RECORD | X | GRANTED | 5 | | RECORD | X,GAP | GRANTED | 20 | +-----------+-----------+-------------+-----------+ 4 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12840 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12839, ACTIVE 110 sec 3 lock struct(s), heap size 1128, 3 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 182 localhost root TABLE LOCK table `study`.`student_scores` trx id 12839 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12839 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080110; asc ;; 3: len 4; hex 4a6f686e; asc John;; 4: len 1; hex 8b; asc ;; 5: len 4; hex 80000046; asc F;; Record lock, heap no 7 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 000000003223; asc 2#;; 2: len 7; hex 810000010c0110; asc ;; 3: len 5; hex 4e69636b79; asc Nicky;; 4: len 1; hex 85; asc ;; 5: len 4; hex 8000000a; asc ;; RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12839 lock_mode X locks gap before rec Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; 4: len 1; hex 8c; asc ;; 5: len 4; hex 8000005a; asc Z;; Next-key lock # Differ from gap lock in whether owning locks for the gap itself.\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where id \u0026lt;= 20 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 5 | Nicky | 5 | 10 | | 10 | John | 11 | 70 | | 20 | Tom | 12 | 90 | +----+-------+-----+-------+ 3 rows in set (0.00 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+-----------+-------------+-----------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+-----------+-------------+-----------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | 10 | | RECORD | X | GRANTED | 20 | | RECORD | X | GRANTED | 5 | +-----------+-----------+-------------+-----------+ 4 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12841 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12840, ACTIVE 69 sec 2 lock struct(s), heap size 1128, 3 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 192 localhost root TABLE LOCK table `study`.`student_scores` trx id 12840 lock mode IX RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12840 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000000a; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080110; asc ;; 3: len 4; hex 4a6f686e; asc John;; 4: len 1; hex 8b; asc ;; 5: len 4; hex 80000046; asc F;; Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108011d; asc ;; 3: len 3; hex 546f6d; asc Tom;; 4: len 1; hex 8c; asc ;; 5: len 4; hex 8000005a; asc Z;; Record lock, heap no 7 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000005; asc ;; 1: len 6; hex 000000003223; asc 2#;; 2: len 7; hex 810000010c0110; asc ;; 3: len 5; hex 4e69636b79; asc Nicky;; 4: len 1; hex 85; asc ;; 5: len 4; hex 8000000a; asc ;; Secondary index # mysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from student_scores where age \u0026gt; 13 for update; +----+-------+-----+-------+ | id | name | age | score | +----+-------+-----+-------+ | 50 | Rose | 14 | 85 | | 30 | Jerry | 15 | 95 | +----+-------+-----+-------+ 2 rows in set (0.00 sec) mysql\u0026gt; select LOCK_TYPE, LOCK_MODE, LOCK_STATUS, LOCK_DATA from performance_schema.data_locks; +-----------+---------------+-------------+------------------------+ | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | LOCK_DATA | +-----------+---------------+-------------+------------------------+ | TABLE | IX | GRANTED | NULL | | RECORD | X | GRANTED | supremum pseudo-record | | RECORD | X | GRANTED | 15, 30 | | RECORD | X | GRANTED | 14, 50 | | RECORD | X,REC_NOT_GAP | GRANTED | 30 | | RECORD | X,REC_NOT_GAP | GRANTED | 50 | +-----------+---------------+-------------+------------------------+ 6 rows in set (0.01 sec) mysql\u0026gt; show engine innodb status\\G /* ------------ TRANSACTIONS ------------ Trx id counter 12842 Purge done for trx's n:o \u0026lt; 12832 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 281480132365440, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132364648, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 281480132363856, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 12841, ACTIVE 1276 sec 3 lock struct(s), heap size 1128, 5 row lock(s) MySQL thread id 9, OS thread handle 6122926080, query id 198 localhost root TABLE LOCK table `study`.`student_scores` trx id 12841 lock mode IX RECORD LOCKS space id 159 page no 6 n bits 80 index idx_age of table `study`.`student_scores` trx id 12841 lock_mode X Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; Record lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 1; hex 8f; asc ;; 1: len 4; hex 8000001e; asc ;; Record lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 1; hex 8e; asc ;; 1: len 4; hex 80000032; asc 2;; RECORD LOCKS space id 159 page no 4 n bits 80 index PRIMARY of table `study`.`student_scores` trx id 12841 lock_mode X locks rec but not gap Record lock, heap no 4 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 8000001e; asc ;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 8100000108012a; asc *;; 3: len 5; hex 4a65727279; asc Jerry;; 4: len 1; hex 8f; asc ;; 5: len 4; hex 8000005f; asc _;; Record lock, heap no 6 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 4; hex 80000032; asc 2;; 1: len 6; hex 000000003217; asc 2 ;; 2: len 7; hex 81000001080144; asc D;; 3: len 4; hex 526f7365; asc Rose;; 4: len 1; hex 8e; asc ;; 5: len 4; hex 80000055; asc U;; Reference # understand-the-basics-of-locks-and-deadlocks-in-mysql-part-i mysql-deadlocks\n"}),e.add({id:23,href:"/docs/eng/airflow/delay/",title:"Delay",description:"",content:""}),e.add({id:24,href:"/docs/eng/mysql/isolation/",title:"Isolation",description:"Setup DROP TABLE IF EXISTS IsolationTests; CREATE TABLE IsolationTests ( Col1 INT, Col2 INT, Col3 INT ); INSERT INTO IsolationTests(Col1,Col2,Col3) SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 ; Read Uncommitted # -- T1 - T2 SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; BEGIN; BEGIN; UPDATE IsolationTests SET Col1 = 2; -- Dirty Read.",content:` Setup DROP TABLE IF EXISTS IsolationTests; CREATE TABLE IsolationTests ( Col1 INT, Col2 INT, Col3 INT ); INSERT INTO IsolationTests(Col1,Col2,Col3) SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 UNION ALL SELECT 1,2,3 ; Read Uncommitted # -- T1 - T2 SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; BEGIN; BEGIN; UPDATE IsolationTests SET Col1 = 2; -- Dirty Read. DO sleep(10); SELECT * FROM IsolationTests; ROLLBACK; COMMIT; Read Committed # If the transaction isolation level is REPEATABLE READ (the default level), all consistent reads within the same transaction read the snapshot established by the first such read in that transaction. You can get a fresher snapshot for your queries by committing the current transaction and after that issuing new queries. With READ COMMITTED isolation level, each consistent read within a transaction sets and reads its own fresh snapshot.
This is called multi-versioned concurrency control. It increases transaction concurrency by split read from write and reduce locked read. By split read from write, we mean that read request in snapshot data will no more acquire lock contention with write request. It\u0026rsquo;s the optimistic read lock in transaction.
-- T1 -- T2 SET TRANSACTION ISOLATION LEVEL READ COMMITTED; SET TRANSACTION ISOLATION LEVEL READ COMMITTED; BEGIN; BEGIN; -- Before T1.update : Col1 = 1 SELECT * FROM IsolationTests; UPDATE IsolationTests SET Col1 = 2; -- After T1.update : Col1 = 2. Unrepeatable read DO sleep(10); SELECT * FROM IsolationTests; ROLLBACK; COMMIT; Repeatable Read (Default) # -- T1 -- T2 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; BEGIN; BEGIN; -- Before T1.update : Col1 = 1 SELECT * FROM IsolationTests; UPDATE IsolationTests SET Col1 = 2; DO sleep(10); -- After T1.update : Col1 = 1 ROLLBACK; SELECT * FROM IsolationTests; COMMIT; Repeatable Read (Phantom Read) # -- T1 -- T2 SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; SET TRANSACTION ISOLATION LEVEL REPEATABLE READ ; BEGIN; BEGIN; -- Before T1.commit : empty set SELECT * FROM IsolationTests where Col1=2; INSERT INTO IsolationTests values (2,2,3) COMMIT; -- After T1.commit : empty set SELECT * FROM IsolationTests where Col1=2; -- Update column, forced latest snapshot : success UPDATE IsolationTests SET Col2=3, Col3=4 where Col1=2; -- Phantom Read : Col (2, 3, 4) SELECT * FROM IsolationTests where Col1=2; COMMIT; Reference # innodb-consistent-read
sql-server-isolation-levels-by-example
`}),e.add({id:25,href:"/docs/eng/airflow/dead-lock/",title:"Dead Lock",description:"",content:""}),e.add({id:26,href:"/docs/eng/airflow/poke/",title:"Poke",description:"",content:""}),e.add({id:27,href:"/docs/eng/spark/dag/",title:"Dag",description:`Shuffle\u0026amp;Exchange
scala\u0026gt; val n2 = spark.range(1, 1000000) scala\u0026gt; val n2split = n2.repartition(7); scala\u0026gt; n2split.take(2).foreach(println) stage2 run take in one task, or in one concurrency Partitions
scala\u0026gt; val ds1 = spark.range(1, 1000000) scala\u0026gt; val ds2 = spark.range(1, 1000000, 2) scala\u0026gt; val ds3 = ds1.repartition(7) scala\u0026gt; val ds4 = ds2.repartition(9) scala\u0026gt; val ds5 = ds3.selectExpr(\u0026quot;id * 5 as id\u0026quot;) scala\u0026gt; val joined = ds5.join(ds4, \u0026quot;id\u0026quot;) scala\u0026gt; val sum = joined.selectExpr(\u0026quot;sum(id)\u0026quot;) Job3 \u0026amp; Job4 both run range() -\u0026gt; partition(), 10 tasks, producing partitions Job5 reads partitions with 9 tasks, broadcast result in memory cuz the result is small enough Job6 reads partitions with 7 tasks, run id * 5 -\u0026gt; join(in memory) Job7 run take with 1 task Reference # Nice Gitbook about Spark How To Read Spark DAGs`,content:`Shuffle\u0026amp;Exchange
scala\u0026gt; val n2 = spark.range(1, 1000000) scala\u0026gt; val n2split = n2.repartition(7); scala\u0026gt; n2split.take(2).foreach(println) stage2 run take in one task, or in one concurrency Partitions
scala\u0026gt; val ds1 = spark.range(1, 1000000) scala\u0026gt; val ds2 = spark.range(1, 1000000, 2) scala\u0026gt; val ds3 = ds1.repartition(7) scala\u0026gt; val ds4 = ds2.repartition(9) scala\u0026gt; val ds5 = ds3.selectExpr(\u0026quot;id * 5 as id\u0026quot;) scala\u0026gt; val joined = ds5.join(ds4, \u0026quot;id\u0026quot;) scala\u0026gt; val sum = joined.selectExpr(\u0026quot;sum(id)\u0026quot;) Job3 \u0026amp; Job4 both run range() -\u0026gt; partition(), 10 tasks, producing partitions Job5 reads partitions with 9 tasks, broadcast result in memory cuz the result is small enough Job6 reads partitions with 7 tasks, run id * 5 -\u0026gt; join(in memory) Job7 run take with 1 task Reference # Nice Gitbook about Spark How To Read Spark DAGs
`}),e.add({id:28,href:"/docs/eng/spark/",title:"Spark",description:"",content:""}),e.add({id:29,href:"/docs/eng/k8s/rbac/",title:"Rbac",description:`Serviceaccount with admin role for quick account setup.
--- apiVersion: v1 kind: ServiceAccount metadata: name: airflow-worker namespace: airflow --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods\u0026quot;, \u0026quot;pods/log\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods/exec\u0026quot;] verbs: [\u0026quot;create\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to roleRef: apiGroup: rbac.`,content:`Serviceaccount with admin role for quick account setup.
--- apiVersion: v1 kind: ServiceAccount metadata: name: airflow-worker namespace: airflow --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods\u0026quot;, \u0026quot;pods/log\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;pods/exec\u0026quot;] verbs: [\u0026quot;create\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: airflow-worker namespace: airflow # Should be namespace you are granting access to roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: airflow-worker # Should match name of Role subjects: - namespace: airflow kind: ServiceAccount name: airflow-worker # Should match service account name, above `}),e.add({id:30,href:"/docs/lang/java/retrofit_okhttp/",title:"Retrofit Okhttp",description:`Hope that I will never bother with making http requests in Java.
@Configuration @Slf4j public class Config { public Retrofit retrofit(ObjectMapper objectMapper, CustomProperties properties) { HttpLoggingInterceptor logging = new HttpLoggingInterceptor(message -\u0026gt; { if (log.isDebugEnabled()) { log.debug(message); } }); logging.setLevel(HttpLoggingInterceptor.Level.BODY); OkHttpClient client = new OkHttpClient.Builder() .readTimeout(Duration.ofSeconds(5L)) .writeTimeout(Duration.ofSeconds(5L)) .connectTimeout(Duration.ofSeconds(3L)) .addInterceptor(chain -\u0026gt; chain.proceed(chain.request().newBuilder() .header(\u0026quot;AUTHORIZATION-NAME\u0026quot;, properties.authName) .header(\u0026quot;AUTHORIZATION-TOKEN\u0026quot;, properties.authToken) .header(\u0026quot;DATA-ENVIRONMENT\u0026quot;, properties.authEnv) .build())) .addInterceptor(logging) .build(); return new Retrofit.Builder() .baseUrl(properties.url) .client(client) .addConverterFactory(JacksonConverterFactory.create(objectMapper)) .build(); } protected interface Service { @POST(\u0026quot;/api/post\u0026quot;) Call\u0026lt;Resposne\u0026gt; saveAndSubmit(@Body Request req); @GET(\u0026quot;/api/query\u0026quot;) Call\u0026lt;Response\u0026gt; query(@Query(value = \u0026quot;param\u0026quot;) String param); } @Bean public Service service(Retrofit retrofit) { return retrofit().`,content:`Hope that I will never bother with making http requests in Java.
@Configuration @Slf4j public class Config { public Retrofit retrofit(ObjectMapper objectMapper, CustomProperties properties) { HttpLoggingInterceptor logging = new HttpLoggingInterceptor(message -\u0026gt; { if (log.isDebugEnabled()) { log.debug(message); } }); logging.setLevel(HttpLoggingInterceptor.Level.BODY); OkHttpClient client = new OkHttpClient.Builder() .readTimeout(Duration.ofSeconds(5L)) .writeTimeout(Duration.ofSeconds(5L)) .connectTimeout(Duration.ofSeconds(3L)) .addInterceptor(chain -\u0026gt; chain.proceed(chain.request().newBuilder() .header(\u0026quot;AUTHORIZATION-NAME\u0026quot;, properties.authName) .header(\u0026quot;AUTHORIZATION-TOKEN\u0026quot;, properties.authToken) .header(\u0026quot;DATA-ENVIRONMENT\u0026quot;, properties.authEnv) .build())) .addInterceptor(logging) .build(); return new Retrofit.Builder() .baseUrl(properties.url) .client(client) .addConverterFactory(JacksonConverterFactory.create(objectMapper)) .build(); } protected interface Service { @POST(\u0026quot;/api/post\u0026quot;) Call\u0026lt;Resposne\u0026gt; saveAndSubmit(@Body Request req); @GET(\u0026quot;/api/query\u0026quot;) Call\u0026lt;Response\u0026gt; query(@Query(value = \u0026quot;param\u0026quot;) String param); } @Bean public Service service(Retrofit retrofit) { return retrofit().create(Service.class); } } `}),e.add({id:31,href:"/docs/eng/k8s/mysql_deploy/",title:"Mysql Deploy",description:`Single node mysql deployment.
--- apiVersion: v1 # API version kind: Service # Type of kubernetes resource metadata: name: mysql # Name of the resource labels: # Labels that will be applied to the resource app: mysql namespace: airflow spec: ports: - port: 3306 selector: app: mysql clusterIP: 10.96.144.158 --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config namespace: airflow # Extra configurations # set innodb_lock_wait_timeout=100; data: my.cnf: |- [mysqld] max_connections = 4096 binlog_expire_logs_seconds = 3600 explicit_defaults_for_timestamp = 1 --- apiVersion: apps/v1 kind: Deployment # Type of the kubernetes resource metadata: name: mysql # Name of the deployment labels: # Labels applied to this deployment app: mysql namespace: airflow spec: selector: matchLabels: # This deployment applies to the Pods matching the specified labels app: mysql strategy: type: Recreate template: # Template for the Pods in this deployment metadata: labels: # Labels to be applied to the Pods in this deployment app: mysql spec: # The spec for the containers that will be run inside the Pods in this deployment nodeSelector: database: accept tolerations: - key: node-role.`,content:"Single node mysql deployment.\n--- apiVersion: v1 # API version kind: Service # Type of kubernetes resource metadata: name: mysql # Name of the resource labels: # Labels that will be applied to the resource app: mysql namespace: airflow spec: ports: - port: 3306 selector: app: mysql clusterIP: 10.96.144.158 --- apiVersion: v1 kind: ConfigMap metadata: name: mysql-config namespace: airflow # Extra configurations # set innodb_lock_wait_timeout=100; data: my.cnf: |- [mysqld] max_connections = 4096 binlog_expire_logs_seconds = 3600 explicit_defaults_for_timestamp = 1 --- apiVersion: apps/v1 kind: Deployment # Type of the kubernetes resource metadata: name: mysql # Name of the deployment labels: # Labels applied to this deployment app: mysql namespace: airflow spec: selector: matchLabels: # This deployment applies to the Pods matching the specified labels app: mysql strategy: type: Recreate template: # Template for the Pods in this deployment metadata: labels: # Labels to be applied to the Pods in this deployment app: mysql spec: # The spec for the containers that will be run inside the Pods in this deployment nodeSelector: database: accept tolerations: - key: node-role.kubernetes.io/master operator: Equal effect: NoSchedule containers: - image: mysql:8 # The container image name: mysql securityContext: runAsUser: 0 env: # Environment variables passed to the container - name: MYSQL_ROOT_PASSWORD valueFrom: # Read environment variables from kubernetes secrets secretKeyRef: name: mysql-root-pass-96h4525584 key: password - name: MYSQL_DATABASE valueFrom: secretKeyRef: name: mysql-db-url-cdthkb6gg6 key: database - name: MYSQL_USER valueFrom: secretKeyRef: name: mysql-user-pass-2bg297f5c9 key: username - name: MYSQL_PASSWORD valueFrom: secretKeyRef: name: mysql-user-pass-2bg297f5c9 key: password ports: - containerPort: 3306 # The port that the container exposes name: mysql volumeMounts: - name: mysql-persistent-storage # This name should match the name specified in `volumes.name` mountPath: /var/lib/mysql - name: mysql-config mountPath: /etc/mysql/conf.d volumes: - name: mysql-persistent-storage hostPath: path: /mnt/airflow/data - name: mysql-config configMap: name: mysql-config "}),e.add({id:32,href:"/docs/eng/k8s/",title:"K8s",description:"",content:""}),e.add({id:33,href:"/docs/eng/ansible/example/",title:"Example",description:"--- - name: \u0026quot;k8s ops\u0026quot; # Create a hosts file , and use -i \u0026lt;host_file\u0026gt; hosts: k8s become: yes become_user: yi.wu remote_user: yi.wu tasks: - name: \u0026quot;Playbook\u0026quot; # Run shell command shell: \u0026quot;sudo docker pull alpine:3.16\u0026quot; # Command args args: # Use bash executable: \u0026quot;/bin/bash\u0026quot; # Capture output register: output - debug: var=output.stdout_lines ",content:"--- - name: \u0026quot;k8s ops\u0026quot; # Create a hosts file , and use -i \u0026lt;host_file\u0026gt; hosts: k8s become: yes become_user: yi.wu remote_user: yi.wu tasks: - name: \u0026quot;Playbook\u0026quot; # Run shell command shell: \u0026quot;sudo docker pull alpine:3.16\u0026quot; # Command args args: # Use bash executable: \u0026quot;/bin/bash\u0026quot; # Capture output register: output - debug: var=output.stdout_lines "}),e.add({id:34,href:"/docs/eng/ansible/localhost/",title:"Localhost",description:"--- - name: \u0026quot;Playing with Ansible\u0026quot; hosts: localhost connection: local tasks: - name: \u0026quot;ls -l\u0026quot; shell: \u0026quot;hostname\u0026quot; register: \u0026quot;output\u0026quot; - debug: var=output.stdout_lines ",content:"--- - name: \u0026quot;Playing with Ansible\u0026quot; hosts: localhost connection: local tasks: - name: \u0026quot;ls -l\u0026quot; shell: \u0026quot;hostname\u0026quot; register: \u0026quot;output\u0026quot; - debug: var=output.stdout_lines "}),e.add({id:35,href:"/docs/eng/ansible/",title:"Ansible",description:"",content:""}),e.add({id:36,href:"/docs/eng/airflow/google_oauth/",title:"Google Oauth",description:`Implement AirflowSecurityManager, and put it under any PYTHONPATH in Airflow.
import logging import os from typing import Any, List, Union, Dict from airflow.www.fab_security.sqla.models import Permission from airflow.www.security import AirflowSecurityManager log = logging.getLogger(__name__) log.setLevel(os.getenv(\u0026quot;AIRFLOW__LOGGING__FAB_LOGGING_LEVEL\u0026quot;, \u0026quot;INFO\u0026quot;)) FAB_ADMIN_ROLE = \u0026quot;Admin\u0026quot; FAB_OP_ROLE = \u0026quot;Op\u0026quot; FAB_VIEWER_ROLE = \u0026quot;Viewer\u0026quot; FAB_PUBLIC_ROLE = \u0026quot;Public\u0026quot; class GoogleAuthorizer(AirflowSecurityManager): def get_role_permissions_from_db(self, role_id: int) -\u0026gt; List[Permission]: pass def get_oauth_user_info( self, provider: str, resp: Any ) -\u0026gt; Dict[str, Union[str, List[str]]]: authorized_hd = 'shopee.com' me = self.`,content:`Implement AirflowSecurityManager, and put it under any PYTHONPATH in Airflow.
import logging import os from typing import Any, List, Union, Dict from airflow.www.fab_security.sqla.models import Permission from airflow.www.security import AirflowSecurityManager log = logging.getLogger(__name__) log.setLevel(os.getenv(\u0026quot;AIRFLOW__LOGGING__FAB_LOGGING_LEVEL\u0026quot;, \u0026quot;INFO\u0026quot;)) FAB_ADMIN_ROLE = \u0026quot;Admin\u0026quot; FAB_OP_ROLE = \u0026quot;Op\u0026quot; FAB_VIEWER_ROLE = \u0026quot;Viewer\u0026quot; FAB_PUBLIC_ROLE = \u0026quot;Public\u0026quot; class GoogleAuthorizer(AirflowSecurityManager): def get_role_permissions_from_db(self, role_id: int) -\u0026gt; List[Permission]: pass def get_oauth_user_info( self, provider: str, resp: Any ) -\u0026gt; Dict[str, Union[str, List[str]]]: authorized_hd = 'shopee.com' me = self.appbuilder.sm.oauth_remotes[provider].get(\u0026quot;userinfo\u0026quot;) data = me.json() log.info('google oauth user: %s', data) if data['hd'] != authorized_hd: return {\u0026quot;username\u0026quot;: \u0026quot;guest\u0026quot;, \u0026quot;role_keys\u0026quot;: [FAB_PUBLIC_ROLE]} else: return { \u0026quot;username\u0026quot;: data.get(\u0026quot;name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;role_keys\u0026quot;: [FAB_OP_ROLE], \u0026quot;first_name\u0026quot;: data.get(\u0026quot;given_name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;last_name\u0026quot;: data.get(\u0026quot;family_name\u0026quot;, \u0026quot;\u0026quot;), \u0026quot;email\u0026quot;: data.get(\u0026quot;email\u0026quot;, \u0026quot;\u0026quot;) } Update \$AIRFLOW_HOME/webserver_config.py. Note that FAB_SECURITY_MANAGER_CLASS is the full package name of the SecurityManager in step1.
import os from flask_appbuilder.const import AUTH_OAUTH basedir = os.path.abspath(os.path.dirname(__file__)) WTF_CSRF_ENABLED = True AUTH_TYPE = AUTH_OAUTH AUTH_ROLES_SYNC_AT_LOGIN = True # Checks roles on every login AUTH_USER_REGISTRATION = ( True # allow users who are not already in the FAB DB to register ) AUTH_ROLES_MAPPING = { \u0026quot;Viewer\u0026quot;: [\u0026quot;Viewer\u0026quot;], \u0026quot;Admin\u0026quot;: [\u0026quot;Admin\u0026quot;], \u0026quot;Op\u0026quot;: [\u0026quot;Op\u0026quot;], } FAB_SECURITY_MANAGER_CLASS = \u0026quot;security_manager.GoogleAuthorizer\u0026quot; GOOGLE_KEY = '' GOOGLE_SECRET_KEY = '' OAUTH_PROVIDERS = [{ 'name': 'google', 'token_key': 'access_token', 'icon': 'fa-google', 'remote_app': { 'api_base_url': 'https://www.googleapis.com/oauth2/v2/', 'client_kwargs': { 'scope': 'email profile', \u0026quot;cookie_policy\u0026quot;: \u0026quot;single_host_origin\u0026quot; }, 'access_token_url': 'https://accounts.google.com/o/oauth2/token', 'authorize_url': 'https://accounts.google.com/o/oauth2/auth', 'request_token_url': None, 'client_id': GOOGLE_KEY, 'client_secret': GOOGLE_SECRET_KEY, } }] `}),e.add({id:37,href:"/docs/eng/airflow/",title:"Airflow",description:"",content:""}),e.add({id:38,href:"/docs/lang/shell/bash/",title:"Bash",description:"script\n## sum with awk awk '{sum += $2} END {print sum}' ## ls sort by file size ls -lh . --sort=size ## cut first field command | cut -f 1 -d '=' ## cut seconds until last fields command | cut -f 2- -d '=' ## git git config --global https.proxy http://127.0.0.1:1086 git config --global https.proxy https://127.0.0.1:1086 git config --global http.proxy socks5://127.0.0.1:1086 git config --global https.proxy socks5://127.0.0.1:1086 git config --global --unset http.",content:"script\n## sum with awk awk '{sum += $2} END {print sum}' ## ls sort by file size ls -lh . --sort=size ## cut first field command | cut -f 1 -d '=' ## cut seconds until last fields command | cut -f 2- -d '=' ## git git config --global https.proxy http://127.0.0.1:1086 git config --global https.proxy https://127.0.0.1:1086 git config --global http.proxy socks5://127.0.0.1:1086 git config --global https.proxy socks5://127.0.0.1:1086 git config --global --unset http.proxy git config --global --unset https.proxy ## count lines wc -l 'find . -name \u0026quot;*.java*\u0026quot;' ## find largest files find -type f -exec du -Sh {} + | sort -rh | head -n 20 ## jq TLS_CRT=$($kubectl_host get secret -n karmada-system karmada-webhook-cert --template='{{ index .data \u0026quot;tls.crt\u0026quot;}}' | tr -d '\\n') TLS_KEY=$($kubectl_host get secret -n karmada-system karmada-webhook-cert --template='{{ index .data \u0026quot;tls.key\u0026quot;}}' | tr -d '\\n') $kubectl_host get secret -n kruise-system kruise-webhook-certs -o json \\ | jq --arg TLS_KEY \u0026quot;$TLS_KEY\u0026quot; '.data[\u0026quot;tls.key\u0026quot;] |= $TLS_KEY' \\ | jq --arg TLS_CRT \u0026quot;$TLS_CRT\u0026quot; '.data[\u0026quot;tls.crt\u0026quot;] |= $TLS_CRT' \\ | jq 'del(.metadata.annotations)' \\ | jq 'del(.metadata.resourceVersion)' \\ | jq 'del(.metadata.uid)' \\ | kubectl apply -f - ## IO iostat -xdm 1 ## CPU mpstat -P ALL lscpu | grep cpu cat /proc/cpuinfo | grep processor ## memory pmap \u0026lt;pid\u0026gt; cat /proc/\u0026lt;pid\u0026gt;/status ## os cat /proc/version uname -a lsb_release -a ## user useradd wuyi passwd wuyi usermod -aG sudo wuyi # add sudoers sudo visudo mysql\nCREATE USER 'repl'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%'; flush privileges; show processlist ; select * from INFORMATION_SCHEMA.PROCESSLIST where id = ''\\G kill mysql_thread_id; show engine innodb status; select trx_id, trx_state, trx_mysql_thread_id, trx_query from information_schema.innodb_trx; show variables like \u0026quot;max_connections\u0026quot;; set global max_connections = 200; show global status like \u0026quot;Com_select\u0026quot;; do sleep(10); show global status like \u0026quot;Com_select\u0026quot;; kubectl\nls -l /sys/fs/cgroup/memory | grep system.slice # get po sort by age kubectl get pod --sort-by=.metadata.creationTimestamp # get po group by hostname kubectl get po -o wide | awk '{print $7}' | sort | uniq -c # port forward kubectl port-forward svc/airflow-webserver 8080:8080 --namespace airflow # upsert configmap kubectl create configmap foo --from-file foo.properties -o yaml --dry-run | kubectl apply -f - "}),e.add({id:39,href:"/docs/lang/shell/",title:"Shell",description:"",content:""}),e.add({id:40,href:"/docs/lang/java/auth_filter/",title:"Auth Filter",description:"@Component @Slf4j @Profile(\u0026quot;!test\u0026quot;) public class GoogleAuthFilter extends OncePerRequestFilter { @Autowired GoogleAuthHolder googleAuthHolder; private void reject(HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED, \u0026quot;unauthorized\u0026quot;); } @SneakyThrows @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) { if (request.getRequestURI().startsWith(AUTH_API_PREFIX)) { var op = Optional.ofNullable(request.getHeader(KEY_TOKEN)) .map(JWT_PATTERN::matcher) .map(m -\u0026gt; m.matches() ? m.group(1) : null) .map(tokenString -\u0026gt; { try { return VERIFIER.verify(tokenString); } catch (Exception e) { log.warn(\u0026quot;GoogleAuth verify failed: {}\u0026quot;, tokenString, e); return null; } }); if (op.",content:"@Component @Slf4j @Profile(\u0026quot;!test\u0026quot;) public class GoogleAuthFilter extends OncePerRequestFilter { @Autowired GoogleAuthHolder googleAuthHolder; private void reject(HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED, \u0026quot;unauthorized\u0026quot;); } @SneakyThrows @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) { if (request.getRequestURI().startsWith(AUTH_API_PREFIX)) { var op = Optional.ofNullable(request.getHeader(KEY_TOKEN)) .map(JWT_PATTERN::matcher) .map(m -\u0026gt; m.matches() ? m.group(1) : null) .map(tokenString -\u0026gt; { try { return VERIFIER.verify(tokenString); } catch (Exception e) { log.warn(\u0026quot;GoogleAuth verify failed: {}\u0026quot;, tokenString, e); return null; } }); if (op.isPresent()) { var payload = op.get().getPayload(); googleAuthHolder.auth = new GoogleAuth((String) payload.get(\u0026quot;email\u0026quot;), (String) payload.get(\u0026quot;sub\u0026quot;), (String) payload.get(\u0026quot;name\u0026quot;), (String) payload.get(\u0026quot;picture\u0026quot;), (String) payload.get(\u0026quot;locale\u0026quot;)); chain.doFilter(request, response); } else { reject(response); } } else { chain.doFilter(request, response); } } } "}),e.add({id:41,href:"/docs/lang/java/exception_handler/",title:"Exception Handler",description:"@RestControllerAdvice @Slf4j public class GlobalExceptionHandler { @ExceptionHandler({BusinessException.class}) protected Response\u0026lt;Object\u0026gt; handleBusinessException(Exception ex, WebRequest request) throws Exception { log.error(\u0026quot;business error\u0026quot;, ex); if (ex instanceof BusinessException be) { return Response.fail(be.code, be.message); } else if (ex.getCause() instanceof BusinessException cbe) { return Response.fail(cbe.code, cbe.message); } else { throw ex; } } } ",content:"@RestControllerAdvice @Slf4j public class GlobalExceptionHandler { @ExceptionHandler({BusinessException.class}) protected Response\u0026lt;Object\u0026gt; handleBusinessException(Exception ex, WebRequest request) throws Exception { log.error(\u0026quot;business error\u0026quot;, ex); if (ex instanceof BusinessException be) { return Response.fail(be.code, be.message); } else if (ex.getCause() instanceof BusinessException cbe) { return Response.fail(cbe.code, cbe.message); } else { throw ex; } } } "}),e.add({id:42,href:"/docs/lang/java/request_correlation/",title:"Request Correlation",description:`Correlate request before and after Spring processing.
Add request_id to request context Add request_id to log4j MDC Add request_id to response Before request
@Configuration @Slf4j public class RequestCorrelationConfig { public static final String KEY_REQUEST_ID = \u0026quot;X-Request-Id\u0026quot;; public static final String KEY_START_TIME = \u0026quot;KEY_START_TIME\u0026quot;; public static class RequestLoggingWithTimeFilter extends CommonsRequestLoggingFilter { @Override protected boolean shouldLog(HttpServletRequest request) { return true; } @Override protected void beforeRequest(HttpServletRequest request, String message) { String requestId = request.`,content:`Correlate request before and after Spring processing.
Add request_id to request context Add request_id to log4j MDC Add request_id to response Before request
@Configuration @Slf4j public class RequestCorrelationConfig { public static final String KEY_REQUEST_ID = \u0026quot;X-Request-Id\u0026quot;; public static final String KEY_START_TIME = \u0026quot;KEY_START_TIME\u0026quot;; public static class RequestLoggingWithTimeFilter extends CommonsRequestLoggingFilter { @Override protected boolean shouldLog(HttpServletRequest request) { return true; } @Override protected void beforeRequest(HttpServletRequest request, String message) { String requestId = request.getHeader(KEY_REQUEST_ID); if (StringUtils.isBlank(requestId)) { requestId = UUID.randomUUID().toString().replace(\u0026quot;-\u0026quot;, \u0026quot;\u0026quot;); } MDC.put(KEY_REQUEST_ID, requestId); request.setAttribute(KEY_REQUEST_ID, requestId); request.setAttribute(KEY_START_TIME, System.currentTimeMillis()); log.info(message); } @Override protected void afterRequest(HttpServletRequest request, String message) { log.info(String.format(\u0026quot;cost: [%dms], %s\u0026quot;, Optional.ofNullable((Long) request.getAttribute(KEY_START_TIME)) .map(s -\u0026gt; System.currentTimeMillis() - s) .orElse(-1L), message)); // !It's potential that MDC is NOT clear correctly. MDC.clear(); } } @Bean public FilterRegistrationBean\u0026lt;RequestLoggingWithTimeFilter\u0026gt; registerRequestLoggingFilter() { var filter = new RequestLoggingWithTimeFilter(); filter.setIncludeQueryString(true); filter.setIncludePayload(true); filter.setMaxPayloadLength(10000); filter.setIncludeHeaders(false); filter.setAfterMessagePrefix(\u0026quot;After request: \u0026quot;); var bean = new FilterRegistrationBean\u0026lt;\u0026gt;(filter); bean.setFilter(filter); bean.setOrder(Ordered.HIGHEST_PRECEDENCE); return bean; } } After request
@RestControllerAdvice public class RequestCorrelationResponseBodyAdvice implements ResponseBodyAdvice\u0026lt;Response\u0026gt; { @Override public boolean supports(MethodParameter returnType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converterType) { return returnType.getParameterType() == Response.class; } @Override public Response beforeBodyWrite(Response body, MethodParameter returnType, MediaType selectedContentType, Class\u0026lt;? extends HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) { if (body != null \u0026amp;\u0026amp; request instanceof ServletServerHttpRequest) { String requestId = ((ServletServerHttpRequest) request).getServletRequest().getAttribute(RequestCorrelationConfig.KEY_REQUEST_ID).toString(); return body.requestId(requestId); } else { return body; } } } `}),e.add({id:43,href:"/docs/lang/java/mdcthreadpool/",title:"MDCThreadpool",description:`Useful thread pool wrapper to pass MDC context across threads.
public class MDCThreadPoolExecutor implements ExecutorService { protected ExecutorService executorService; MDCThreadPoolExecutor() { } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this.executorService = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this.`,content:`Useful thread pool wrapper to pass MDC context across threads.
public class MDCThreadPoolExecutor implements ExecutorService { protected ExecutorService executorService; MDCThreadPoolExecutor() { } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue) { this.executorService = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); } public MDCThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler) { this.executorService = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); } @Override public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { return executorService.submit(MDCWrappers.wrap(task)); } @Override public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result) { return executorService.submit(MDCWrappers.wrap(task), result); } @Override public Future\u0026lt;?\u0026gt; submit(Runnable task) { return executorService.submit(MDCWrappers.wrap(task)); } @Override public \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException { return executorService.invokeAll(MDCWrappers.wrapCollection(tasks)); } @Override public \u0026lt;T\u0026gt; List\u0026lt;Future\u0026lt;T\u0026gt;\u0026gt; invokeAll(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { return executorService.invokeAll(MDCWrappers.wrapCollection(tasks), timeout, unit); } @Override public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) throws InterruptedException, ExecutionException { return executorService.invokeAny(MDCWrappers.wrapCollection(tasks)); } @Override public \u0026lt;T\u0026gt; T invokeAny(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return executorService.invokeAny(MDCWrappers.wrapCollection(tasks), timeout, unit); } @Override public void execute(Runnable command) { executorService.execute(MDCWrappers.wrap(command)); } @Override public void shutdown() { executorService.shutdown(); } @Override public List\u0026lt;Runnable\u0026gt; shutdownNow() { return executorService.shutdownNow(); } @Override public boolean isShutdown() { return executorService.isShutdown(); } @Override public boolean isTerminated() { return executorService.isTerminated(); } @Override public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { return executorService.awaitTermination(timeout, unit); } } public class MDCWrappers { public static Runnable wrap(final Runnable runnable) { final var context = MDC.getCopyOfContextMap(); return () -\u0026gt; { var previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { runnable.run(); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Callable\u0026lt;T\u0026gt; wrap(final Callable\u0026lt;T\u0026gt; callable) { final var context = MDC.getCopyOfContextMap(); return () -\u0026gt; { var previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { return callable.call(); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; wrap(final Consumer\u0026lt;T\u0026gt; consumer) { final Map\u0026lt;String, String\u0026gt; context = MDC.getCopyOfContextMap(); return (t) -\u0026gt; { Map previous = MDC.getCopyOfContextMap(); if (context == null) { MDC.clear(); } else { MDC.setContextMap(context); } try { consumer.accept(t); } finally { if (previous == null) { MDC.clear(); } else { MDC.setContextMap(previous); } } }; } public static \u0026lt;T\u0026gt; Collection\u0026lt;Callable\u0026lt;T\u0026gt;\u0026gt; wrapCollection(Collection\u0026lt;? extends Callable\u0026lt;T\u0026gt;\u0026gt; tasks) { Collection\u0026lt;Callable\u0026lt;T\u0026gt;\u0026gt; wrapped = new ArrayList\u0026lt;\u0026gt;(); for (Callable\u0026lt;T\u0026gt; task : tasks) { wrapped.add(wrap(task)); } return wrapped; } } `}),e.add({id:44,href:"/docs/eng/mysql/",title:"Mysql",description:"",content:""}),e.add({id:45,href:"/docs/lang/golang/distributed_lock/",title:"Distributed Lock",description:`Easy to use Etcd distributed lock, some design pattern are worth thinking.
func (child *Children) WantsToPlay(computer *Computer, timeToEat *sync.WaitGroup) error { defer timeToEat.Done() fmt.Printf(\u0026quot;%s wants to play\\n\u0026quot;, child.name) session, err := concurrency.NewSession(computer.cpu, concurrency.WithTTL(10000)) if err != nil { return err } defer session.Close() seat := concurrency.NewMutex(session, computer.name) if child.isPatient { if err := seat.Lock(context.TODO()); err != nil { return err } } else { if err := seat.TryLock(context.TODO()); err != nil { if err == concurrency.`,content:`Easy to use Etcd distributed lock, some design pattern are worth thinking.
func (child *Children) WantsToPlay(computer *Computer, timeToEat *sync.WaitGroup) error { defer timeToEat.Done() fmt.Printf(\u0026quot;%s wants to play\\n\u0026quot;, child.name) session, err := concurrency.NewSession(computer.cpu, concurrency.WithTTL(10000)) if err != nil { return err } defer session.Close() seat := concurrency.NewMutex(session, computer.name) if child.isPatient { if err := seat.Lock(context.TODO()); err != nil { return err } } else { if err := seat.TryLock(context.TODO()); err != nil { if err == concurrency.ErrLocked { fmt.Printf(\u0026quot;someone else is playing, %s impatientlly leaves\\n\u0026quot;, child.name) return nil } else { return err } } } fmt.Printf(\u0026quot;%s is playing his favorite game: %s\\n\u0026quot;, child.name, child.favoriteGame) time.Sleep(time.Duration(rand.Int()%10+1) * time.Second) fmt.Printf(\u0026quot;%s is having fun\\n\u0026quot;, child.name) if err := seat.Unlock(context.TODO()); err != nil { return err } return nil } Lease And Keepalive # sequenceDiagram Client-\u0026gt;\u0026gt;+Server: Lease(ttl=T) Server--\u0026gt;\u0026gt;Client: Granted rect rgb(191, 223, 255) loop Every T/N note right of Client: Keepalive Loop. \u0026lt;br /\u0026gt;Client sends request to refresh lease every T/N, \u0026lt;br /\u0026gt; to keepalive the lease. \u0026lt;br /\u0026gt; Client-\u0026gt;\u0026gt;+Server: Refresh Lease(ttl=T) Server--\u0026gt;\u0026gt;-Client: Refershed end end Client-\u0026gt;\u0026gt;Server: I'm done Server--\u0026gt;\u0026gt;-Client: Released Reference # How Linux Cron Works Cron Distributed In Golang Next Distributed Lock In Etcd `}),e.add({id:46,href:"/docs/lang/golang/",title:"Golang",description:"",content:""}),e.add({id:47,href:"/docs/lang/java/",title:"Java",description:"",content:""}),e.add({id:48,href:"/docs/intro/dg/",title:"Welcome",description:"",content:`
`}),e.add({id:49,href:"/docs/",title:"Docs",description:"Docs Doks.",content:`Here are some docs.
`}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()